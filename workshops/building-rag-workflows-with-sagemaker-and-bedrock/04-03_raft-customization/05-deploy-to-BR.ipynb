{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad542e7-9ef8-41d1-9d6c-3c6c2efb7f19",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Hosting SageMaker AI models in Bedrock with Bedrock Custom Model Import\n",
    "\n",
    "In this notebook, you'll take a model artifact that you trained with Amazon SageMaker AI and host it in Amazon Bedrock using Bedrock Custom Model Import.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19163cfd-f05e-47ca-b086-a17163a2269a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdb17ac-0844-4f99-bfd6-7f5ea7952b38",
   "metadata": {},
   "source": [
    "## Global variables\n",
    "\n",
    "This section contains python variables used in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ab776e2-a4a8-41bc-899f-4e46e6b2b413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-west-2-340043819279\n",
      "340043819279\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "print(bucket_name)\n",
    "print(account_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5ed653",
   "metadata": {},
   "source": [
    "# Import SageMaker AI fine-tuned Model to Amazon Bedrock\n",
    "\n",
    "This notebook demonstrates how to import models to Amazon Bedrock using Custom Model Import (CMI) feature.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- An AWS account with access to Amazon Bedrock\n",
    "- Appropriate IAM roles and permissions for Bedrock and Amazon S3, following [the instruction here](https://docs.aws.amazon.com/bedrock/latest/userguide/model-import-iam-role.html)\n",
    "- A S3 bucket prepared to store the custom model\n",
    "- Sufficient local storage space (At least 17GB for 8B and 135GB for 70B models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4dc696",
   "metadata": {},
   "source": [
    "### Step 1: Verify S3 Path\n",
    "\n",
    "Update these parameters according to your AWS environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0cef38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix = f'llama3-1-8b-merge-adapter-2025-03-25-00-31-59-900/output/model/merged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be27120c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-340043819279/llama3-1-8b-merge-adapter-2025-03-25-00-31-59-900/output/model/merged/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_s3_path = f\"s3://{bucket_name}/{s3_prefix}/\"\n",
    "full_s3_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c7b98a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-25 00:37:51        906 config.json\n",
      "2025-03-25 00:38:30        184 generation_config.json\n",
      "2025-03-25 00:37:42 4886466168 model-00001-of-00007.safetensors\n",
      "2025-03-25 00:37:59 4832007448 model-00002-of-00007.safetensors\n",
      "2025-03-25 00:37:31 4999813112 model-00003-of-00007.safetensors\n",
      "2025-03-25 00:38:08 4999813128 model-00004-of-00007.safetensors\n",
      "2025-03-25 00:37:51 4832007496 model-00005-of-00007.safetensors\n",
      "2025-03-25 00:38:15 4999813120 model-00006-of-00007.safetensors\n",
      "2025-03-25 00:38:24 2571158184 model-00007-of-00007.safetensors\n",
      "2025-03-25 00:37:51      23950 model.safetensors.index.json\n",
      "2025-03-25 00:37:42        325 special_tokens_map.json\n",
      "2025-03-25 00:38:07    9085657 tokenizer.json\n",
      "2025-03-25 00:37:31      55380 tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {full_s3_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30269e4b-5993-48d7-a99e-c98861bc7dbf",
   "metadata": {},
   "source": [
    "The Bedrock Custom Model Import job requires a service role to run. The appropriate policies can be found in the [CMI documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-import-iam-role.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62501f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%m-%d-%Y-%H%M%S\")\n",
    "role_name = \"bedrock-cmi-role\" #replace with your own bedrock service role name if different\n",
    "\n",
    "\n",
    "# Define your parameters (please update this part based on your setup)\n",
    "imported_model_name = 'Fine-Tuned-RAFT' # E.x. Deepseek-8B-model\n",
    "job_name = imported_model_name + '-' + timestamp # E.x. Deepseek-8B-job\n",
    "role_arn = f'arn:aws:iam::{account_id}:role/{role_name}' # Please make sure it has sufficient permission as listed in the pre-requisite\n",
    "\n",
    "# Region (currently only 'us-west-2' and 'us-east-1' support CMI with Deepseek-Distilled-Llama models)\n",
    "region_info = sagemaker_session.boto_region_name#'us-west-2' # You can modify to 'us-east-1' based on your need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e552c110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fine-Tuned-RAFT-03-28-2025-150703'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b9ae8e",
   "metadata": {},
   "source": [
    "### Step 2: Create Custom Model Import Job\n",
    "\n",
    "Initialize the import job in Amazon Bedrock\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>Note:</b> Creating CMI job for 8B model could take 5-20 minutes to complete.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1715643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model import job created with ARN: arn:aws:bedrock:us-west-2:340043819279:model-import-job/vbzwuxncklo7\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Bedrock client\n",
    "bedrock = boto3.client('bedrock', region_name=region_info)\n",
    "\n",
    "s3_uri = f's3://{bucket_name}/{s3_prefix}/'\n",
    "\n",
    "# Create the model import job\n",
    "response = bedrock.create_model_import_job(\n",
    "    jobName=job_name,\n",
    "    importedModelName=imported_model_name,\n",
    "    roleArn=role_arn,\n",
    "    modelDataSource={\n",
    "        's3DataSource': {\n",
    "            's3Uri': s3_uri\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "job_Arn = response['jobArn']\n",
    "\n",
    "# Output the job ARN\n",
    "print(f\"Model import job created with ARN: {response['jobArn']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ff649",
   "metadata": {},
   "source": [
    "### Step 3: Monitor Import Job Status\n",
    "\n",
    "Check the status of your import job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e69f88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: INPROGRESS\n",
      "Status: INPROGRESS\n",
      "Status: INPROGRESS\n",
      "Status: INPROGRESS\n",
      "Status: INPROGRESS\n",
      "Status: INPROGRESS\n",
      "Status: INPROGRESS\n",
      "Status: INPROGRESS\n",
      "Status: INPROGRESS\n",
      "Status: COMPLETED\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Check CMI job status\n",
    "while True:\n",
    "    response = bedrock.get_model_import_job(jobIdentifier=job_Arn)\n",
    "    status = response['status'].upper()\n",
    "    print(f\"Status: {status}\")\n",
    "    \n",
    "    if status in ['COMPLETED', 'FAILED']:\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)  # Check every 60 seconds\n",
    "\n",
    "# Get the model ID\n",
    "model_id = response['importedModelArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec66d12c",
   "metadata": {},
   "source": [
    "### Step 4: Wait for Model Initialization\n",
    "\n",
    "Allow time for the model to initialize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0f501fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:bedrock:us-west-2:340043819279:imported-model/gh3v4a6z3l69'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a53bca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for 5mins for cold start \n",
    "time.sleep(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a438cae",
   "metadata": {},
   "source": [
    "### Step 5: Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd1b9b83-8b2d-4395-8b53-9726ddc44014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.config import Config\n",
    "import json\n",
    "\n",
    "def format_messages(messages: list[dict[str, str]]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Format messages for Llama 3+ chat models.\n",
    "    \n",
    "    The model only supports 'system', 'user' and 'assistant' roles, starting with 'system', then 'user' and \n",
    "    alternating (u/a/u/a/u...). The last message must be from 'user'.\n",
    "    \"\"\"\n",
    "    # auto assistant suffix\n",
    "    # messages.append({\"role\": \"assistant\"})\n",
    "    \n",
    "    output = \"<|begin_of_text|>\"\n",
    "    # Adding an inferred prefix\n",
    "    system_prefix = f\"\\n\\nCutting Knowledge Date: December 2024\\nToday Date: {datetime.now().strftime('%d %b %Y')}\\n\\n\"\n",
    "    for i, entry in enumerate(messages):\n",
    "        output += f\"<|start_header_id|>{entry['role']}<|end_header_id|>\"\n",
    "        if entry['role'] == 'system':\n",
    "            output += f\"{system_prefix}{entry['content']}<|eot_id|>\"\n",
    "        elif entry['role'] != 'system' and 'content' in entry:\n",
    "            output += f\"\\n\\n{entry['content']}<|eot_id|>\"\n",
    "    output += \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "    return output\n",
    "\n",
    "\n",
    "def send_prompt(messages, temperature=0.3, max_tokens=4096, top_p=0.9, continuation=False, max_retries=10):\n",
    "    # convert u/a format \n",
    "    frmt_input = format_messages(messages)\n",
    "\n",
    "    client = boto3.Session().client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=region_info,\n",
    "    config=Config(\n",
    "        connect_timeout=300,  # 5 minutes\n",
    "        read_timeout=300,     # 5 minutes\n",
    "        retries={'max_attempts': 3}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            response = client.invoke_model(\n",
    "                modelId=model_id,\n",
    "                body=json.dumps({\n",
    "                    'prompt': frmt_input,\n",
    "                    'temperature': temperature,\n",
    "                    'max_gen_len': max_tokens,\n",
    "                    'top_p': top_p\n",
    "                }),\n",
    "                accept='application/json',\n",
    "                contentType='application/json'\n",
    "            )\n",
    "            \n",
    "            result = json.loads(response['body'].read().decode('utf-8'))\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "            attempt += 1\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(30)\n",
    "    \n",
    "    raise Exception(\"Failed to get response after maximum retries\")\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb0fe7dc-f652-4a99-b7aa-873abe0f0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_messages(data):\n",
    "    system_content = f\"\"\"You are an assistant for question-answering tasks. Answer the following question in 5 sentences using the provided context. If you don't know the answer, just say \"I don't know.\".\"\"\"\n",
    "    user_content = f\"\"\"\n",
    "        Context: {data[\"CONTEXT\"]} \n",
    "        \n",
    "        Question: {data[\"QUESTION\"]}\n",
    "        \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_content},\n",
    "        {\"role\": \"user\", \"content\": user_content}\n",
    "    ]\n",
    "    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cadfa900-b822-44bd-87a5-482b784e6d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "test_dataset = load_dataset(\"json\", data_files=\"../data/sft_test_data.json\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0df94d85-3233-458a-bdf3-84508ffcac5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CONTEXT': 'The aim of this study was to detect anti-topoisomerase I (anti-topo I) autoantibodies, which are known to be limited in systemic sclerosis patients, in silicosis patients with no clinical symptoms of autoimmune disease.\\n\\nSerum anti-topo I autoantibodies were detected using ELISA. Differences in clinical parameters between patients with and without anti-topo I autoantibodies were analyzed.\\n\\nSeven of 69 patients had anti-topo I autoantibodies. These 7 patients showed elevated PaCO(2) values (P=0.0212), and inverse correlations between serum soluble Fas levels and PaCO(2) values were found.\\n\\nSINV (TR339-eGFP) (+) strand RNA, infectious virus titers and infection rates transiently increased in mosquitoes following dsRNA injection to cognate Ago2, Dcr2, or TSN mRNAs. Detection of SINV RNA-derived small RNAs at 2 and 7 days post-infection in non-silenced mosquitoes provided important confirmation of RNAi pathway activity. Two different recombinant SINV viruses (MRE16-eGFP and TR339-eGFP) with significant differences in infection kinetics were used to delineate vector/virus interactions in the midgut. We show virus-dependent effects on RNAi component transcript and protein levels during infection. Monitoring midgut Ago2, Dcr2, and TSN transcript levels during infection revealed that only TSN transcripts were significantly increased in midguts over blood-fed controls. Ago2 protein levels were depleted immediately following a non-infectious bloodmeal and varied during SINV infection in a virus-dependent manner.\\n\\nFifty-four of the 56 cases that met inclusion criteria demonstrated significant intra-epithelial lymphocytosis as the predominant histologic abnormality; however, none were associated with H. pylori infection by IHC staining. Two cases that also showed a prominent intra-epithelial and lamina propria neutrophilic infiltrate were both positive for H. pylori and were excluded from further study. Of the 36 small bowel biopsies available, 19 (53%) showed changes in CD.\\n\\nWBC was associated with 24-h EE adjusted for age, sex, fat-free mass, and fat mass (r=0.13, P=0.04). In SAAT, tumor necrosis factor-alpha (TNF-alpha), shown as log10-transformed TNF-alpha (r=0.36, P=0.05), and plasminogen activator inhibitor-1 (PAI-1), shown as log10-transformed PAI-1 (lPAI-1; r=0.41, P=0.02), expressions were also positively correlated with adjusted 24-h EE. lPAI-1 was also correlated with adjusted sleep EE (r=0.34, P=0.07).',\n",
       " 'ORACLE': 'The aim of this study was to detect anti-topoisomerase I (anti-topo I) autoantibodies, which are known to be limited in systemic sclerosis patients, in silicosis patients with no clinical symptoms of autoimmune disease.\\n\\nSerum anti-topo I autoantibodies were detected using ELISA. Differences in clinical parameters between patients with and without anti-topo I autoantibodies were analyzed.\\n\\nSeven of 69 patients had anti-topo I autoantibodies. These 7 patients showed elevated PaCO(2) values (P=0.0212), and inverse correlations between serum soluble Fas levels and PaCO(2) values were found.',\n",
       " 'DISTRACTED': False,\n",
       " 'QUESTION': 'Do detection of anti-topoisomerase I autoantibody in patients with silicosis?',\n",
       " 'ANSWER': ' Yes, the study detected anti-topoisomerase I autoantibodies in 7 out of 69 patients with silicosis. These patients were identified using the ELISA method. The presence of anti-topo I autoantibodies was associated with elevated PaCO2 values in these patients. Additionally, an inverse correlation was found between serum soluble Fas levels and PaCO2 values in these patients. The study aimed to investigate the presence of anti-topo I autoantibodies in silicosis patients without clinical symptoms of autoimmune disease.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_item = test_dataset[2]\n",
    "test_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9afba42-4ae9-4a56-9b35-5a397bc7a7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed: An error occurred (ModelNotReadyException) when calling the InvokeModel operation (reached max retries: 3): Model is not ready for inference. Wait and try your request again. Refer to https://docs.aws.amazon.com/bedrock/latest/userguide/invoke-imported-model.html#handle-model-not-ready-exception.\n",
      "Attempt 2 failed: An error occurred (ModelNotReadyException) when calling the InvokeModel operation (reached max retries: 3): Model is not ready for inference. Wait and try your request again. Refer to https://docs.aws.amazon.com/bedrock/latest/userguide/invoke-imported-model.html#handle-model-not-ready-exception.\n",
      "\n",
      "    ============== Question ============\n",
      "    Do detection of anti-topoisomerase I autoantibody in patients with silicosis?\n",
      "    \n",
      "    ========= Generated Answer =========\n",
      "    {'generation': '        Answer: Yes, the study detected anti-topoisomerase I autoantibodies in 7 out of 69 patients with silicosis. These autoantibodies were found using an ELISA test. The presence of anti-topo I autoantibodies was associated with elevated PaCO2 values in these patients. The study suggests that anti-topoisomerase I autoantibodies may be present in a subset of silicosis patients. The detection of these autoantibodies may have implications for the diagnosis and treatment of silicosis.', 'prompt_token_count': 706, 'generation_token_count': 115, 'stop_reason': 'stop'}\n",
      "\n",
      "    ======== Ground Truth Answer =======\n",
      "     Yes, the study detected anti-topoisomerase I autoantibodies in 7 out of 69 patients with silicosis. These patients were identified using the ELISA method. The presence of anti-topo I autoantibodies was associated with elevated PaCO2 values in these patients. Additionally, an inverse correlation was found between serum soluble Fas levels and PaCO2 values in these patients. The study aimed to investigate the presence of anti-topo I autoantibodies in silicosis patients without clinical symptoms of autoimmune disease.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "messages = build_messages(test_item)\n",
    "\n",
    "model_response = send_prompt(messages)\n",
    "\n",
    "print(f\"\"\"\n",
    "    ============== Question ============\n",
    "    {test_item[\"QUESTION\"]}\n",
    "    \n",
    "    ========= Generated Answer =========\n",
    "    {model_response}\n",
    "\n",
    "    ======== Ground Truth Answer =======\n",
    "    {test_item[\"ANSWER\"]}\n",
    "    \"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
