{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8fd722b-7c0b-4813-ae7f-963215645fb9",
   "metadata": {},
   "source": [
    "# ðŸš€ Deploy Your Fine-tuned RAFT Model with Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a414500-d1e8-40d8-ac2c-861f385014fc",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23e8cc62-53a9-4542-a566-56f47ada5e24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.11/site-packages (0.4.1)\n",
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.19.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.11/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.29.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
      "Using cached evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: evaluate\n",
      "  Attempting uninstall: evaluate\n",
      "    Found existing installation: evaluate 0.4.1\n",
      "    Uninstalling evaluate-0.4.1:\n",
      "      Successfully uninstalled evaluate-0.4.1\n",
      "Successfully installed evaluate-0.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting rouge-score\n",
      "  Using cached rouge_score-0.1.2-py3-none-any.whl\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.11/site-packages (from rouge-score) (2.1.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.11/site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.11/site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk->rouge-score) (8.1.8)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk->rouge-score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from nltk->rouge-score) (4.67.1)\n",
      "Installing collected packages: rouge-score\n",
      "Successfully installed rouge-score-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting bleu\n",
      "  Using cached bleu-0.3-py3-none-any.whl\n",
      "Collecting efficiency (from bleu)\n",
      "  Using cached efficiency-2.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from efficiency->bleu) (2.2.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from efficiency->bleu) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->efficiency->bleu) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->efficiency->bleu) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->efficiency->bleu) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->efficiency->bleu) (1.17.0)\n",
      "Using cached efficiency-2.0-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: efficiency, bleu\n",
      "Successfully installed bleu-0.3 efficiency-2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a4f9750-ff90-4985-a978-52b22dbab4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "from typing import List, Dict\n",
    "from datetime import datetime\n",
    "from sagemaker.huggingface import (\n",
    "    HuggingFaceModel, \n",
    "    get_huggingface_llm_image_uri\n",
    ")\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import JSONSerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe509d4a-91e5-4826-8cd5-8be23ffe875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_region = boto3.Session().region_name\n",
    "session = sagemaker.session.Session(boto_session=boto3.Session(region_name=boto_region))\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf03803d-3b72-4a27-861c-2af12106fa18",
   "metadata": {},
   "source": [
    "## Deploy using DJL-Inference Container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f92ece7-9d1f-4ffd-a056-583e4a0222cc",
   "metadata": {},
   "source": [
    "The [Deep Java Library (DJL) Large Model Inference (LMI)](https://docs.aws.amazon.com/sagemaker/latest/dg/large-model-inference-container-docs.html) containers are specialized Docker containers designed to facilitate the deployment of large language models (LLMs) on Amazon SageMaker. These containers integrate a model server with optimized inference libraries, providing a comprehensive solution for serving LLMs. \n",
    "\n",
    "**Key Features of DJL LMI Containers:**\n",
    "\n",
    "* __Optimized Inference Performance__: Support for popular model architectures like DeepSeek, Mistral, Llama, Falcon and many more..\n",
    "* __Integration with Inference Libraries__: Seamless integration with libraries such as vLLM, TensorRT-LLM, and Transformers NeuronX.\n",
    "* __Advanced Capabilities__: Features like continuous batching, token streaming, quantization (e.g., AWQ, GPTQ, FP8), multi-GPU inference using tensor parallelism, and support for LoRA fine-tuned models.\n",
    "\n",
    "**Benefits for Deploying LLMs with DJL-LMI on Amazon SageMaker:**\n",
    "\n",
    "* __Simplified Deployment__: DJL LMI containers offer a low-code interface, allowing users to specify configurations like model parallelization and optimization settings through a configuration file. \n",
    "* __Performance Optimization__: By leveraging optimized inference libraries and techniques, these containers enhance inference performance, reducing latency and improving throughput.\n",
    "* __Scalability__: Designed to handle large models that may not fit on a single accelerator, enabling efficient scaling across multiple GPUs or specialized hardware like AWS Inferentia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b78106-b50f-4a26-afda-d0a865d3a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmi_container_uri = f\"763104351884.dkr.ecr.{boto_region}.amazonaws.com/djl-inference:0.31.0-lmi13.0.0-cu124\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1121de3-6465-4bcb-a026-9e7b896cc261",
   "metadata": {},
   "source": [
    "Choose an appropriate model name and endpoint name when hosting your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e01dabec-ad96-4476-8da8-4028983b8a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base: \n",
      "llama-3-1-8B-base-lmi-250330-213014-ep\n",
      "tuned: \n",
      "llama-3-1-8B-tuned-lmi-250330-213014-ep\n"
     ]
    }
   ],
   "source": [
    "model_timestamp = datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "\n",
    "base_model_name = f\"llama-3-1-8B-base-lmi-{model_timestamp}\"\n",
    "tuned_model_name = f\"llama-3-1-8B-tuned-lmi-{model_timestamp}\"\n",
    "\n",
    "base_endpoint_name = f\"{base_model_name}-ep\"\n",
    "tuned_endpoint_name = f\"{tuned_model_name}-ep\"\n",
    "\n",
    "print(f\"base: \\n{base_endpoint_name}\")\n",
    "print(f\"tuned: \\n{tuned_endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976098f1-4cdc-4405-8022-07432ced6d1b",
   "metadata": {},
   "source": [
    "Create a new [SageMaker Model](https://sagemaker.readthedocs.io/en/stable/api/inference/model.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e65d9f4",
   "metadata": {},
   "source": [
    "> âš  Swap `HF_MODEL_ID` with another model tag if you want to compare against a different base model.\n",
    ">\n",
    "> Gated models will require you to supply a HuggingFace API Token via the `HF_TOKEN: \"hf_...\"` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b508a0a3-dab1-4880-8eb0-76b82ebbb4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set these to either S3 paths or HuggingFace model tags\n",
    "\n",
    "BASE_MODEL_ARTIFACTS =  \"<<PATH_TO_YOUR_BASE_MODEL>>\"\n",
    "TUNED_MODEL_ARTIFACTS = \"<<PATH_TO_YOUR_TUNED_MERGED_MODEL>>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8622d23d-b59c-4aa8-8cec-3d5e3be19ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = sagemaker.Model(\n",
    "    image_uri=lmi_container_uri,\n",
    "    env={\n",
    "        \"HF_MODEL_ID\": BASE_MODEL_ARTIFACTS,\n",
    "        \"OPTION_MAX_MODEL_LEN\": \"5000\",\n",
    "        \"OPTION_GPU_MEMORY_UTILIZATION\": \"0.95\",\n",
    "        \"OPTION_ENABLE_STREAMING\": \"false\",\n",
    "        \"OPTION_ROLLING_BATCH\": \"auto\",\n",
    "        \"OPTION_MODEL_LOADING_TIMEOUT\": \"3600\",\n",
    "        \"OPTION_PAGED_ATTENTION\": \"false\",\n",
    "        \"OPTION_DTYPE\": \"fp16\",\n",
    "    },\n",
    "    role=role,\n",
    "    name=base_model_name,\n",
    "    sagemaker_session=sagemaker.Session()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cd7e15a5-5897-4187-b22d-20ff0d94ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = sagemaker.Model(\n",
    "    image_uri=lmi_container_uri,\n",
    "    env={\n",
    "        \"HF_MODEL_ID\": TUNED_MODEL_ARTIFACTS,\n",
    "        \"OPTION_MAX_MODEL_LEN\": \"5000\",\n",
    "        \"OPTION_GPU_MEMORY_UTILIZATION\": \"0.95\",\n",
    "        \"OPTION_ENABLE_STREAMING\": \"false\",\n",
    "        \"OPTION_ROLLING_BATCH\": \"auto\",\n",
    "        \"OPTION_MODEL_LOADING_TIMEOUT\": \"3600\",\n",
    "        \"OPTION_PAGED_ATTENTION\": \"false\",\n",
    "        \"OPTION_DTYPE\": \"fp16\",\n",
    "    },\n",
    "    role=role,\n",
    "    name=tuned_model_name,\n",
    "    sagemaker_session=sagemaker.Session()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1ac41f-8586-491b-8bcc-621b527d1f0c",
   "metadata": {},
   "source": [
    "ðŸš€ Deploy. Please wait for the endpoint to be `InService` before running inference against it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c550b451-6ad6-46c5-b104-6739683b365b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!\n",
      "Your BASE Endpoint: llama-3-1-8B-sft-lmi-250329-032857-ep is now deployed! ðŸš€\n"
     ]
    }
   ],
   "source": [
    "base_model_predictor = base_model.deploy(\n",
    "    endpoint_name=base_endpoint_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    container_startup_health_check_timeout=600,\n",
    "    wait=True\n",
    ")\n",
    "print(f\"\\nYour BASE Endpoint: {base_endpoint_name} is now deployed! ðŸš€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "192bb6a4-76c5-4ab7-93a6-5d080a391a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!\n",
      "Your TUNED Endpoint: llama-3-1-8B-tuned-lmi-250330-213014-ep is now deployed! ðŸš€\n"
     ]
    }
   ],
   "source": [
    "tuned_model_predictor = tuned_model.deploy(\n",
    "    endpoint_name=tuned_endpoint_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    container_startup_health_check_timeout=600,\n",
    "    wait=True\n",
    ")\n",
    "print(f\"\\nYour TUNED Endpoint: {tuned_endpoint_name} is now deployed! ðŸš€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481d9178-dade-44c4-b633-99f500b20de6",
   "metadata": {},
   "source": [
    "### Inference with SageMaker SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc27b2d-78a0-42a0-8605-8c94d4e5fd89",
   "metadata": {},
   "source": [
    "SageMaker python sdk simplifies the inference construct using `sagemaker.Predictor` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2d357e-d4e3-4297-a4cd-6dc45d12630e",
   "metadata": {},
   "source": [
    "Llama 3 utilizes the following prompt format:\n",
    "\n",
    "\n",
    "```json\n",
    "<|begin_of_text|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "You are an assistant for question-answering tasks. Answer the following question in 5 sentences using the provided context. If you don't know the answer, just say \"I don't know.\".\n",
    "\n",
    "<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Context: {CONTEXT}\n",
    "\n",
    "Question: {QUESTION} \n",
    "<|eot_id|>\n",
    "\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1d0096cd-5ccb-4885-85b4-d986ce7711ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_messages(messages: list[dict[str, str]]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Format messages for Llama 3+ chat models.\n",
    "    \n",
    "    The model only supports 'system', 'user' and 'assistant' roles, starting with 'system', then 'user' and \n",
    "    alternating (u/a/u/a/u...). The last message must be from 'user'.\n",
    "    \"\"\"\n",
    "    # auto assistant suffix\n",
    "    # messages.append({\"role\": \"assistant\"})\n",
    "    \n",
    "    output = \"<|begin_of_text|>\"\n",
    "    # Adding an inferred prefix\n",
    "    system_prefix = f\"\\n\\nCutting Knowledge Date: December 2024\\nToday Date: {datetime.now().strftime('%d %b %Y')}\\n\\n\"\n",
    "    for i, entry in enumerate(messages):\n",
    "        output += f\"<|start_header_id|>{entry['role']}<|end_header_id|>\"\n",
    "        if entry['role'] == 'system':\n",
    "            output += f\"{system_prefix}{entry['content']}<|eot_id|>\"\n",
    "        elif entry['role'] != 'system' and 'content' in entry:\n",
    "            output += f\"\\n\\n{entry['content']}<|eot_id|>\"\n",
    "    output += \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "    return output\n",
    "\n",
    "\n",
    "def send_prompt(predictor, messages, parameters):\n",
    "    # convert u/a format \n",
    "    frmt_input = format_messages(messages)\n",
    "    payload = {\n",
    "        \"inputs\": frmt_input,\n",
    "        \"parameters\": parameters\n",
    "    }\n",
    "    response = predictor.predict(payload)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a1a840f9-34ce-400c-a597-08ce2242e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_messages(data):\n",
    "    system_content = f\"\"\"You are an assistant for question-answering tasks. Answer the following question in 5 sentences using the provided context. If you don't know the answer, just say \"I don't know.\".\"\"\"\n",
    "    user_content = f\"\"\"\n",
    "        Context: {data[\"context\"]} \n",
    "        \n",
    "        Question: {data[\"question\"]}\n",
    "        \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_content},\n",
    "        {\"role\": \"user\", \"content\": user_content}\n",
    "    ]\n",
    "    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bcf7f7-8f5e-4468-ae53-343ccba7c586",
   "metadata": {},
   "source": [
    "We can continue to use a simple `List[Dict[str, str]]` format to chat and simplify `system`, `user` and `assistant` chat transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "595d8e4c-8ab0-4036-9cd0-b1a88803ec91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c61de8599cc40218896692a1cc6367b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "test_dataset = load_dataset(\"json\", data_files=\"datasets/raft/test/test.json\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e40538b5-5e23-4179-be92-0a277de181f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'synthetic_answer': \" Yes, UCP2 deficiency helps to restrict the pathogenesis of experimental cutaneous and visceral leishmaniosis in mice. This is evident from the significantly lower parasite loads found in infected UCP2KO mice compared to infected wild-type mice. Additionally, UCP2KO mice produced higher levels of certain cytokines, such as IFN-Î³, IL-17, and IL-13, which suggests an enhanced immune response against Leishmania infection. The results indicate that UCP2 plays a role in facilitating the infection by suppressing the host's immune response. Overall, the study suggests that UCP2 deficiency could be beneficial in the context of Leishmania infection.\",\n",
       " 'distracted': True,\n",
       " 'original_answer': 'In this way, UCP2KO mice were better able than their WT counterparts to overcome L. major and L. infantum infections. These findings suggest that upregulating host ROS levels, perhaps by inhibiting UPC2, may be an effective approach to preventing leishmaniosis.',\n",
       " 'question': 'Does uCP2 deficiency help to restrict the pathogenesis of experimental cutaneous and visceral leishmaniosis in mice?',\n",
       " 'context': 'Regular low aspirin use may reduce the risk of esophagogastric cancer. Laparoscopic resection of locally advanced gastric cancer appears equivalent to open resection. There is no survival benefit for the addition of postoperative radiation therapy to adjuvant chemotherapy after primary gastric cancer resection. For tumors of the esophagus and gastroesophageal junction, the combination of preoperative radiation therapy with concurrent chemotherapy may be required to ensure achievement of a negative surgical margin and to reduce local tumor recurrence. Epirubicin may not add benefit to fluorinated pyrimidine and platinum-based chemotherapy, either in the preoperative setting or in the treatment of metastatic disease. The Her2-targeted agents lapatinib and trastuzumab emtansine failed to improve outcome when either added to or compared with chemotherapy. Immune checkpoint inhibition appears to be active in metastatic gastric cancer.\\n\\nPlantaris muscles from alcohol-fed rats displayed extensive atrophy, as well as decreased GSH levels, a trend for decreased total antioxidant potential and elevated atrogin-1 and MuRF-1 mRNA levels. GSH levels and total antioxidant potential continued to decrease during 2 weeks of ABS from alcohol, which were normalized in abstinent rats provided PRO. Gene levels of both E3 ligases returned to baseline during ABS. In parallel, plantaris cross-sectional area increased in both groups during ABS.\\n\\nDespite modern advances in treatment, skin cancer is still one of the most common causes of death in the western countries. Chemotherapy plays an important role in melanoma management. Tamoxifen has been used either alone or in- combination with other chemotherapeutic agents to treat melanoma. However, response rate of tamoxifen as a single agent has been comparatively low. In the present study, we investigated whether treatment with methyl-Î²-cyclodextrin (MCD), a cholesterol depleting agent, increases the efficacy of tamoxifen in melanoma cells.',\n",
       " 'oracle': 'Uncoupling protein 2 (UCP2) is a mitochondrial transporter that has been shown to lower the production of reactive oxygen species (ROS). Intracellular pathogens such as Leishmania upregulate UCP2 and thereby suppress ROS production in infected host tissues, allowing the multiplication of parasites within murine phagocytes. This makes host UCP2 and ROS production potential targets in the development of antileishmanial therapies. Here we explore how UCP2 affects the outcome of cutaneous leishmaniosis (CL) and visceral leishmaniosis (VL) in wild-type (WT) C57BL/6 mice and in C57BL/6 mice lacking the UCP2 gene (UCP2KO).\\n\\nTo investigate the effects of host UCP2 deficiency on Leishmania infection, we evaluated parasite loads and cytokine production in target organs. Parasite loads were significantly lower in infected UCP2KO mice than in infected WT mice. We also found that UCP2KO mice produced significantly more interferon-Î³ (IFN-Î³), IL-17 and IL-13 than WT mice (P<0.05), suggesting that UCP2KO mice are resistant to Leishmania infection.',\n",
       " 'prompt': '\\n        <|begin_of_text|>\\n        <|start_header_id|>system<|end_header_id|>\\n        You are an assistant for question-answering tasks. Answer the following question in 5 sentences using the provided context. If you don\\'t know the answer, just say \"I don\\'t know.\".\\n        <|start_header_id|>user<|end_header_id|>\\n        Context: Regular low aspirin use may reduce the risk of esophagogastric cancer. Laparoscopic resection of locally advanced gastric cancer appears equivalent to open resection. There is no survival benefit for the addition of postoperative radiation therapy to adjuvant chemotherapy after primary gastric cancer resection. For tumors of the esophagus and gastroesophageal junction, the combination of preoperative radiation therapy with concurrent chemotherapy may be required to ensure achievement of a negative surgical margin and to reduce local tumor recurrence. Epirubicin may not add benefit to fluorinated pyrimidine and platinum-based chemotherapy, either in the preoperative setting or in the treatment of metastatic disease. The Her2-targeted agents lapatinib and trastuzumab emtansine failed to improve outcome when either added to or compared with chemotherapy. Immune checkpoint inhibition appears to be active in metastatic gastric cancer.\\n\\nPlantaris muscles from alcohol-fed rats displayed extensive atrophy, as well as decreased GSH levels, a trend for decreased total antioxidant potential and elevated atrogin-1 and MuRF-1 mRNA levels. GSH levels and total antioxidant potential continued to decrease during 2 weeks of ABS from alcohol, which were normalized in abstinent rats provided PRO. Gene levels of both E3 ligases returned to baseline during ABS. In parallel, plantaris cross-sectional area increased in both groups during ABS.\\n\\nDespite modern advances in treatment, skin cancer is still one of the most common causes of death in the western countries. Chemotherapy plays an important role in melanoma management. Tamoxifen has been used either alone or in- combination with other chemotherapeutic agents to treat melanoma. However, response rate of tamoxifen as a single agent has been comparatively low. In the present study, we investigated whether treatment with methyl-Î²-cyclodextrin (MCD), a cholesterol depleting agent, increases the efficacy of tamoxifen in melanoma cells.\\n        \\n        Question: Does uCP2 deficiency help to restrict the pathogenesis of experimental cutaneous and visceral leishmaniosis in mice?\\n        <|start_header_id|>assistant<|end_header_id|> \\n        Answer: Yes, UCP2 deficiency helps to restrict the pathogenesis of experimental cutaneous and visceral leishmaniosis in mice. This is evident from the significantly lower parasite loads found in infected UCP2KO mice compared to infected wild-type mice. Additionally, UCP2KO mice produced higher levels of certain cytokines, such as IFN-Î³, IL-17, and IL-13, which suggests an enhanced immune response against Leishmania infection. The results indicate that UCP2 plays a role in facilitating the infection by suppressing the host\\'s immune response. Overall, the study suggests that UCP2 deficiency could be beneficial in the context of Leishmania infection.'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_item = test_dataset[0]\n",
    "test_item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5974fe3f-c1f0-4f76-9060-4e9878d6aa31",
   "metadata": {},
   "source": [
    "reloading the predictors from endpoint names in case we are working with existing endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "faf7bd10-062b-4397-8ae9-2eb366aabda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictor = sagemaker.Predictor(\n",
    "    endpoint_name=\"<<YOUR_BASE_ENDPOINT_NAME>\", #base_endpoint_name,\n",
    "    sagemaker_session=session,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")\n",
    "\n",
    "tuned_predictor = sagemaker.Predictor(\n",
    "    endpoint_name=\"<<YOUR_TUNED_ENDPOINT_NAME>>\", #tuned_endpoint_name,\n",
    "    sagemaker_session=session,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c49b7ec8-72b2-4ab7-a93a-0d0e4c2dfa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ============== Question ============\n",
      "    Does uCP2 deficiency help to restrict the pathogenesis of experimental cutaneous and visceral leishmaniosis in mice?\n",
      "\n",
      "    ========= Baseline Answer ==========\n",
      "    I don't know.\n",
      "    \n",
      "    ========= Generated Answer =========\n",
      "            Answer: Yes, the study suggests that UCP2 deficiency helps to restrict the pathogenesis of experimental cutaneous and visceral leishmaniasis in mice. This is evident from the reduced parasite load in the spleen and liver of UCP2-deficient mice compared to wild-type mice. The absence of UCP2 also resulted in a lower parasite load in the footpads of mice infected with L. major. Additionally, UCP2-deficient mice showed a lower parasite load in the liver and spleen after infection with L. donovani. Overall, the results indicate that UCP2 deficiency may have a protective effect against leishmaniasis.\n",
      "\n",
      "    ======== Ground Truth Answer =======\n",
      "     Yes, UCP2 deficiency helps to restrict the pathogenesis of experimental cutaneous and visceral leishmaniosis in mice. This is evident from the significantly lower parasite loads found in infected UCP2KO mice compared to infected wild-type mice. Additionally, UCP2KO mice produced higher levels of certain cytokines, such as IFN-Î³, IL-17, and IL-13, which suggests an enhanced immune response against Leishmania infection. The results indicate that UCP2 plays a role in facilitating the infection by suppressing the host's immune response. Overall, the study suggests that UCP2 deficiency could be beneficial in the context of Leishmania infection.\n",
      "    \n",
      "CPU times: user 14.6 ms, sys: 146 Î¼s, total: 14.7 ms\n",
      "Wall time: 1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "messages = build_messages(test_item)\n",
    "\n",
    "base_response = send_prompt(\n",
    "    base_predictor,\n",
    "    messages,\n",
    "    parameters={\n",
    "        \"temperature\": 0.9, \n",
    "        \"max_new_tokens\": 512,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    ")\n",
    "\n",
    "tuned_response = send_prompt(\n",
    "    tuned_predictor,\n",
    "    messages,\n",
    "    parameters={\n",
    "        \"temperature\": 0.9, \n",
    "        \"max_new_tokens\": 512,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"\"\"\n",
    "    ============== Question ============\n",
    "    {test_item[\"question\"]}\n",
    "\n",
    "    ========= Baseline Answer ==========\n",
    "    {base_response['generated_text']}\n",
    "    \n",
    "    ========= Generated Answer =========\n",
    "    {tuned_response['generated_text']}\n",
    "\n",
    "    ======== Ground Truth Answer =======\n",
    "    {test_item[\"synthetic_answer\"]}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ef576e-e03f-47f3-914b-f302642891fc",
   "metadata": {},
   "source": [
    "## Evaluate your results\n",
    "\n",
    "In this section, you will build a dataset of evaluation data. The `MAX_EVALUATIONS` value will limit the scope of the evaluation and the time it takes to complete.\n",
    "\n",
    "Since there are pure distractor documents from splitting our training dataset, we will remove them during the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b160e750-d509-4486-84c2-dc3fcbc193db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:evaluate.loading:Using the latest cached version of the module from /home/sagemaker-user/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--bleu/9e0985c1200e367cce45605ce0ecb5ede079894e0f24f54613fca08eeb8aff76 (last modified on Tue Mar 25 03:00:37 2025) since it couldn't be found locally at evaluate-metric--bleu, or remotely on the Hugging Face Hub.\n",
      "WARNING:evaluate.loading:Using the latest cached version of the module from /home/sagemaker-user/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--rouge/b01e0accf3bd6dd24839b769a5fda24e14995071570870922c71970b3a6ed886 (last modified on Tue Mar 25 03:07:28 2025) since it couldn't be found locally at evaluate-metric--rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3997 of 4000"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750dba3f922a4304a032758fec8f4a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5988578"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = []\n",
    "oracle_context = []\n",
    "test_context = []\n",
    "ground_truth = []\n",
    "base_predictions = []\n",
    "sft_predictions = []\n",
    "\n",
    "#evaluation_data = {}\n",
    "\n",
    "MAX_EVALUATIONS = -1 #set to -1 to run the entire dataset. WARNING: THIS WILL TAKE A LONG TIME\n",
    "\n",
    "if MAX_EVALUATIONS > -1:\n",
    "    print(f\"MAX_EVALUATIONS set, reducing input to {MAX_EVALUATIONS} items.\")\n",
    "else:\n",
    "    MAX_EVALUATIONS = len(test_dataset)\n",
    "\n",
    "for idx, test_item in enumerate(test_dataset.select(range(MAX_EVALUATIONS))):\n",
    "    \n",
    "    if test_item[\"distracted\"] == True:\n",
    "        continue #skip distractor docs\n",
    "\n",
    "    \n",
    "    messages = build_messages(test_item)\n",
    "    \n",
    "    base_response = send_prompt(\n",
    "        base_predictor,\n",
    "        messages,\n",
    "        parameters={\n",
    "            \"temperature\": 0.9, \n",
    "            \"max_new_tokens\": 512,\n",
    "            \"top_p\": 0.9\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    sft_response = send_prompt(\n",
    "        tuned_predictor,\n",
    "        messages,\n",
    "        parameters={\n",
    "            \"temperature\": 0.9, \n",
    "            \"max_new_tokens\": 512,\n",
    "            \"top_p\": 0.9\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Define the candidate predictions and reference sentences\n",
    "\n",
    "    # evaluation_data.append({\n",
    "    #     \"ground_truth\": test_item[\"ANSWER\"],\n",
    "    #     \"base\": base_response['generated_text'],\n",
    "    #     \"tuned\": sft_response['generated_text'],\n",
    "    #     \"test_context\": test_item[\"CONTEXT\"],\n",
    "    #     \"oracle_context\": test_item[\"ORACLE\"]\n",
    "    # })\n",
    "    \n",
    "    ground_truth.append(test_item[\"synthetic_answer\"])\n",
    "    base_predictions.append(base_response['generated_text'])\n",
    "    sft_predictions.append(sft_response['generated_text'])\n",
    "\n",
    "    print(f\"{idx} of {MAX_EVALUATIONS}\", end=\"\\r\")\n",
    "    \n",
    "\n",
    "evaluation_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"ground_truth\": ground_truth, \n",
    "        \"base\": base_predictions, \n",
    "        \"tuned\": sft_predictions}\n",
    ")\n",
    "evaluation_dataset.to_json(f\"./eval.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "57b9ba43-35d0-42d6-af9d-41a0c216a4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======BASE MODEL=======\n",
      "{'bleu': 0.4114756154832229, 'precisions': [0.6616061544758556, 0.45710818427201044, 0.3469485627025168, 0.27320760722527254], 'brevity_penalty': 1.0, 'length_ratio': 1.0314523944310647, 'translation_length': 322497, 'reference_length': 312663, 'rouge1': 0.6611250630158876, 'rouge2': 0.4589607151287476, 'rougeL': 0.47945904131584977, 'rougeLsum': 0.47942825228714764}\n",
      "=======TUNED MODEL=======\n",
      "{'bleu': 0.47653356485280896, 'precisions': [0.6957336146068233, 0.516426514730066, 0.41553424995375793, 0.34539467547247255], 'brevity_penalty': 1.0, 'length_ratio': 1.055219197666497, 'translation_length': 329928, 'reference_length': 312663, 'rouge1': 0.711687864095034, 'rouge2': 0.5278652867147173, 'rougeL': 0.5702438779020467, 'rougeLsum': 0.5706031751897982}\n"
     ]
    }
   ],
   "source": [
    "ground_truth = []\n",
    "base_predictions = []\n",
    "sft_predictions = []\n",
    "\n",
    "for eval_item in evaluation_dataset:\n",
    "\n",
    "    ground_truth.append(eval_item[\"ground_truth\"])\n",
    "    base_predictions.append(eval_item['base'])\n",
    "    sft_predictions.append(eval_item['tuned'])\n",
    "\n",
    "\n",
    "base_bleu_results = bleu.compute(predictions=base_predictions, references=ground_truth)\n",
    "base_rouge_results = rouge.compute(predictions=base_predictions, references=ground_truth)\n",
    "\n",
    "# Compute the BLEU score\n",
    "sft_bleu_results = bleu.compute(predictions=sft_predictions, references=ground_truth)\n",
    "sft_rouge_results = rouge.compute(predictions=sft_predictions, references=ground_truth)\n",
    "\n",
    "base_scores = (base_bleu_results | base_rouge_results)\n",
    "sft_scores = (sft_bleu_results | sft_rouge_results)\n",
    "\n",
    "\n",
    "# base_scores.append(base_bleu_results | base_rouge_results)\n",
    "# sft_scores.append(sft_bleu_results | sft_rouge_results)\n",
    "print(\"=======BASE MODEL=======\")\n",
    "print(base_scores)\n",
    "print(\"=======TUNED MODEL=======\")\n",
    "print(sft_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "96ebc86e-9ca8-4f3a-bf93-61e807e61929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dimension</th>\n",
       "      <th>base</th>\n",
       "      <th>tuned</th>\n",
       "      <th>delta</th>\n",
       "      <th>delta_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bleu</td>\n",
       "      <td>0.411476</td>\n",
       "      <td>0.476534</td>\n",
       "      <td>0.065058</td>\n",
       "      <td>15.810888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rouge1</td>\n",
       "      <td>0.661125</td>\n",
       "      <td>0.711688</td>\n",
       "      <td>0.050563</td>\n",
       "      <td>7.647993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rouge2</td>\n",
       "      <td>0.458961</td>\n",
       "      <td>0.527865</td>\n",
       "      <td>0.068905</td>\n",
       "      <td>15.013174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rougeL</td>\n",
       "      <td>0.479459</td>\n",
       "      <td>0.570244</td>\n",
       "      <td>0.090785</td>\n",
       "      <td>18.934847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rougeLsum</td>\n",
       "      <td>0.479428</td>\n",
       "      <td>0.570603</td>\n",
       "      <td>0.091175</td>\n",
       "      <td>19.017428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dimension      base     tuned     delta  delta_percent\n",
       "0       bleu  0.411476  0.476534  0.065058      15.810888\n",
       "1     rouge1  0.661125  0.711688  0.050563       7.647993\n",
       "2     rouge2  0.458961  0.527865  0.068905      15.013174\n",
       "3     rougeL  0.479459  0.570244  0.090785      18.934847\n",
       "4  rougeLsum  0.479428  0.570603  0.091175      19.017428"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {'dimension':[], 'base': [], 'tuned': [], 'delta': [], 'delta_percent': []}\n",
    "\n",
    "for key in base_scores.keys():\n",
    "    if key in [\"length_ratio\",\"precisions\",\"brevity_penalty\",\"translation_length\",\"reference_length\"]:\n",
    "        continue\n",
    "        \n",
    "    delta = sft_scores[key]-base_scores[key]\n",
    "    delta_percent = (delta/base_scores[key])*100\n",
    "    \n",
    "    data['dimension'].append(key)\n",
    "    data['base'].append(base_scores[key])\n",
    "    data['tuned'].append(sft_scores[key])\n",
    "    data['delta'].append(delta)\n",
    "    data['delta_percent'].append(delta_percent)\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d12f13-c803-4ebe-8679-79256aa70f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
