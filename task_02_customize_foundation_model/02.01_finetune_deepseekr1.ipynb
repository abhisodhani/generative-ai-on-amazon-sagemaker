{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune Llama 3.2 3B Instruct with PyTorch FSDP and QLora on Amazon SageMaker AI using interactive @remote decorator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo notebook, we demonstrate how to fine-tune the Meta-Llama-3.2-3B model on SageMaker AI using the @remote decorator for interactively execute Training Jobs directly from the notebook. We also use QLoRA, Hugging Face PEFT, and bitsandbytes.\n",
    "\n",
    "**FSDP + Q-Lora Background**\n",
    "\n",
    "Hugging Face share the support of Q-Lora and PyTorch FSDP (Fully Sharded Data Parallel). FSDP and Q-Lora allows you now to fine-tune Llama-like architectures or Mixtral 8x7B. Hugging Face PEFT is were the core logic resides, read more about it in the [PEFT documentation](https://huggingface.co/docs/peft/v0.10.0/en/accelerate/fsdp).\n",
    "\n",
    "* [PyTorch FSDP](https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/) is a data/model parallelism technique that shards model across GPUs, reducing memory requirements and enabling the training of larger models more efficiently​​​​​​.\n",
    "* Q-LoRA is a fine-tuning method that leverages quantization and Low-Rank Adapters to efficiently reduced computational requirements and memory footprint. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the required libriaries, including the Hugging Face libraries, and **restart** the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:38:06.851473Z",
     "start_time": "2023-07-20T12:38:04.440644Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.48.2 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (4.48.2)\n",
      "Requirement already satisfied: peft==0.14.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: accelerate==1.3.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: bitsandbytes==0.45.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (0.45.1)\n",
      "Requirement already satisfied: datasets==3.2.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (3.2.0)\n",
      "Requirement already satisfied: evaluate==0.4.3 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.4.3)\n",
      "Requirement already satisfied: mlflow in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (2.21.3)\n",
      "Requirement already satisfied: safetensors>=0.5.2 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (0.5.3)\n",
      "Collecting sagemaker==2.239.3 (from -r requirements.txt (line 10))\n",
      "  Downloading sagemaker-2.239.3-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: sagemaker-mlflow==0.1.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (0.1.0)\n",
      "Requirement already satisfied: sentencepiece==0.2.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: scikit-learn==1.6.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (1.6.1)\n",
      "Requirement already satisfied: tokenizers>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (0.21.1)\n",
      "Requirement already satisfied: py7zr in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (0.22.0)\n",
      "Requirement already satisfied: huggingface_hub[hf_transfer] in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.30.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers==4.48.2->-r requirements.txt (line 1)) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.48.2->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers==4.48.2->-r requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.48.2->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.48.2->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers==4.48.2->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers==4.48.2->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft==0.14.0->-r requirements.txt (line 2)) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from peft==0.14.0->-r requirements.txt (line 2)) (2.4.1.post100)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets==3.2.0->-r requirements.txt (line 5)) (15.0.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets==3.2.0->-r requirements.txt (line 5)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets==3.2.0->-r requirements.txt (line 5)) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets==3.2.0->-r requirements.txt (line 5)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets==3.2.0->-r requirements.txt (line 5)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.2.0->-r requirements.txt (line 5)) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets==3.2.0->-r requirements.txt (line 5)) (3.9.5)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r requirements.txt (line 10)) (23.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.35.75 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r requirements.txt (line 10)) (1.36.23)\n",
      "Requirement already satisfied: cloudpickle>=2.2.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r requirements.txt (line 10)) (2.2.1)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r requirements.txt (line 10)) (7.1.0)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r requirements.txt (line 10)) (0.115.11)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r requirements.txt (line 10)) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r requirements.txt (line 10)) (6.10.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r requirements.txt (line 10)) (4.23.0)\n",
      "Requirement already satisfied: omegaconf<=2.3,>=2.2 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r requirements.txt (line 10)) (2.3.0)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r requirements.txt (line 10)) (0.3.2)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r requirements.txt (line 10)) (4.3.6)\n",
      "Requirement already satisfied: protobuf<6.0,>=3.12 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r requirements.txt (line 10)) (3.20.3)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.17 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r requirements.txt (line 10)) (1.0.25)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r requirements.txt (line 10)) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r requirements.txt (line 10)) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r requirements.txt (line 10)) (3.0.0)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r requirements.txt (line 10)) (2.3.0)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r requirements.txt (line 10)) (0.34.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.6.1->-r requirements.txt (line 13)) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.6.1->-r requirements.txt (line 13)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.6.1->-r requirements.txt (line 13)) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[hf_transfer]->-r requirements.txt (line 7)) (4.13.1)\n",
      "Requirement already satisfied: hf-transfer>=0.1.4 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[hf_transfer]->-r requirements.txt (line 7)) (0.1.9)\n",
      "Requirement already satisfied: mlflow-skinny==2.21.3 in /opt/conda/lib/python3.11/site-packages (from mlflow->-r requirements.txt (line 8)) (2.21.3)\n",
      "Requirement already satisfied: Flask<4 in /opt/conda/lib/python3.11/site-packages (from mlflow->-r requirements.txt (line 8)) (3.1.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /opt/conda/lib/python3.11/site-packages (from mlflow->-r requirements.txt (line 8)) (3.1.5)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /opt/conda/lib/python3.11/site-packages (from mlflow->-r requirements.txt (line 8)) (1.15.1)\n",
      "Requirement already satisfied: graphene<4 in /opt/conda/lib/python3.11/site-packages (from mlflow->-r requirements.txt (line 8)) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in /opt/conda/lib/python3.11/site-packages (from mlflow->-r requirements.txt (line 8)) (22.0.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.11/site-packages (from mlflow->-r requirements.txt (line 8)) (3.6)\n",
      "Requirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.11/site-packages (from mlflow->-r requirements.txt (line 8)) (3.10.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from mlflow->-r requirements.txt (line 8)) (2.0.38)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.21.3->mlflow->-r requirements.txt (line 8)) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.21.3->mlflow->-r requirements.txt (line 8)) (8.1.8)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.21.3->mlflow->-r requirements.txt (line 8)) (0.44.1)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.21.3->mlflow->-r requirements.txt (line 8)) (3.1.44)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.21.3->mlflow->-r requirements.txt (line 8)) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.21.3->mlflow->-r requirements.txt (line 8)) (1.30.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.21.3->mlflow->-r requirements.txt (line 8)) (2.10.6)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.21.3->mlflow->-r requirements.txt (line 8)) (0.5.3)\n",
      "Requirement already satisfied: texttable in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 15)) (1.7.0)\n",
      "Requirement already satisfied: pycryptodomex>=3.16.0 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 15)) (3.22.0)\n",
      "Requirement already satisfied: pyzstd>=0.15.9 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 15)) (0.16.2)\n",
      "Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 15)) (1.1.1)\n",
      "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 15)) (1.0.3)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 15)) (0.2.3)\n",
      "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 15)) (1.0.1)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r requirements.txt (line 15)) (1.1.0)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow->-r requirements.txt (line 8)) (1.3.9)\n",
      "Requirement already satisfied: botocore<1.37.0,>=1.36.23 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.35.75->sagemaker==2.239.3->-r requirements.txt (line 10)) (1.36.23)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.35.75->sagemaker==2.239.3->-r requirements.txt (line 10)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.35.75->sagemaker==2.239.3->-r requirements.txt (line 10)) (0.11.3)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /opt/conda/lib/python3.11/site-packages (from fastapi->sagemaker==2.239.3->-r requirements.txt (line 10)) (0.46.0)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /opt/conda/lib/python3.11/site-packages (from Flask<4->mlflow->-r requirements.txt (line 8)) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /opt/conda/lib/python3.11/site-packages (from Flask<4->mlflow->-r requirements.txt (line 8)) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in /opt/conda/lib/python3.11/site-packages (from Flask<4->mlflow->-r requirements.txt (line 8)) (1.9.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0->-r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0->-r requirements.txt (line 5)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0->-r requirements.txt (line 5)) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.2.0->-r requirements.txt (line 5)) (1.18.3)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /opt/conda/lib/python3.11/site-packages (from graphene<4->mlflow->-r requirements.txt (line 8)) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /opt/conda/lib/python3.11/site-packages (from graphene<4->mlflow->-r requirements.txt (line 8)) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /opt/conda/lib/python3.11/site-packages (from graphene<4->mlflow->-r requirements.txt (line 8)) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker==2.239.3->-r requirements.txt (line 10)) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from Jinja2<4,>=2.11->mlflow->-r requirements.txt (line 8)) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow->-r requirements.txt (line 8)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow->-r requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow->-r requirements.txt (line 8)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow->-r requirements.txt (line 8)) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow->-r requirements.txt (line 8)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow->-r requirements.txt (line 8)) (3.2.1)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<=2.3,>=2.2->sagemaker==2.239.3->-r requirements.txt (line 10))\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==3.2.0->-r requirements.txt (line 5)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==3.2.0->-r requirements.txt (line 5)) (2025.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.48.2->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.48.2->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.48.2->-r requirements.txt (line 1)) (2025.1.31)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker==2.239.3->-r requirements.txt (line 10)) (13.9.4)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker==2.239.3->-r requirements.txt (line 10)) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker==2.239.3->-r requirements.txt (line 10)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker==2.239.3->-r requirements.txt (line 10)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker==2.239.3->-r requirements.txt (line 10)) (0.23.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy<3,>=1.4.0->mlflow->-r requirements.txt (line 8)) (3.1.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.14.0->-r requirements.txt (line 2)) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.14.0->-r requirements.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.11/site-packages (from uvicorn->sagemaker==2.239.3->-r requirements.txt (line 10)) (0.14.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from google-pasta->sagemaker==2.239.3->-r requirements.txt (line 10)) (1.17.0)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker==2.239.3->-r requirements.txt (line 10)) (1.7.6.9)\n",
      "Requirement already satisfied: pox>=0.3.4 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker==2.239.3->-r requirements.txt (line 10)) (0.3.5)\n",
      "Requirement already satisfied: google-auth~=2.0 in /opt/conda/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow->-r requirements.txt (line 8)) (2.38.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.21.3->mlflow->-r requirements.txt (line 8)) (4.0.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.11/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow->-r requirements.txt (line 8)) (1.2.18)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /opt/conda/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow->-r requirements.txt (line 8)) (0.51b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow->-r requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow->-r requirements.txt (line 8)) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker==2.239.3->-r requirements.txt (line 10)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker==2.239.3->-r requirements.txt (line 10)) (2.19.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /opt/conda/lib/python3.11/site-packages (from starlette<0.47.0,>=0.40.0->fastapi->sagemaker==2.239.3->-r requirements.txt (line 10)) (4.8.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp->datasets==3.2.0->-r requirements.txt (line 5)) (0.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft==0.14.0->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi->sagemaker==2.239.3->-r requirements.txt (line 10)) (1.3.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow->-r requirements.txt (line 8)) (1.17.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.21.3->mlflow->-r requirements.txt (line 8)) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow->-r requirements.txt (line 8)) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow->-r requirements.txt (line 8)) (4.9)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker==2.239.3->-r requirements.txt (line 10)) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow->-r requirements.txt (line 8)) (0.6.1)\n",
      "Downloading sagemaker-2.239.3-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m137.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?2done\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144592 sha256=34a313f86c8751acc957ae19330cf47d34edfdb794a8bfae4e011de989d0eea9\n",
      "  Stored in directory: /home/sagemaker-user/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, sagemaker\n",
      "  Attempting uninstall: antlr4-python3-runtime\n",
      "    Found existing installation: antlr4-python3-runtime 4.13.2\n",
      "    Uninstalling antlr4-python3-runtime-4.13.2:\n",
      "      Successfully uninstalled antlr4-python3-runtime-4.13.2\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.239.0\n",
      "    Uninstalling sagemaker-2.239.0:\n",
      "      Successfully uninstalled sagemaker-2.239.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "latex2sympy2-extended 1.0.6 requires antlr4-python3-runtime==4.13.2, but you have antlr4-python3-runtime 4.9.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 sagemaker-2.239.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install -r requirements.txt --upgrade\n",
    "# %pip install -q -U python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Setup Configuration file path\n",
    "\n",
    "We are setting the directory in which the config.yaml file resides so that remote decorator can make use of the settings through [SageMaker Defaults](https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk).\n",
    "\n",
    "This notebook is using the Hugging Face container for the `us-east-1` region. Make sure you are using the right image for your AWS region, otherwise edit [config.yaml](./config.yaml). Container Images are available [here](https://github.com/aws/deep-learning-containers/blob/master/available_images.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T09:24:51.291677Z",
     "start_time": "2023-11-15T09:24:51.282905Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Use .env in case of hidden variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set path to config file\n",
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset\n",
    "\n",
    "We are going to load [Samsung/samsum](https://huggingface.co/datasets/Samsung/samsum) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80fdfaee19044cfbbb5b8b7bf22a115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c7617ceea24b31b0db08d90f2b40b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "samsum.py:   0%|          | 0.00/3.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4452478624b540a5baddcc277435c4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "corpus.7z:   0%|          | 0.00/2.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bab668446bc407885414dee057d8f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/14732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9dd6a58462c4d658b0b7dd86d388006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49c7b9a95a347c1aa7b64dcfa38165f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe shape: (500, 3)\n",
      "Number of train elements: 450\n",
      "Number of test elements: 50\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the samsum dataset\n",
    "dataset = load_dataset(\"samsum\", trust_remote_code=True)\n",
    "\n",
    "# Convert the train split to a pandas DataFrame\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "# Optionally limit to first 1000 examples\n",
    "df = df.iloc[0:500]\n",
    "\n",
    "# Preview the data\n",
    "print(\"Original dataframe shape:\", df.shape)\n",
    "df.head()\n",
    "\n",
    "# Split the dataframe into train and test sets\n",
    "train, test = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Number of train elements:\", len(train))\n",
    "print(\"Number of test elements:\", len(test))\n",
    "\n",
    "# If you need to retain the original column structure\n",
    "#print(\"Train dataframe columns:\", train.columns.tolist())\n",
    "#print(\"Test dataframe columns:\", test.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a prompt template and load the dataset with a random sample to try summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "# custom instruct prompt start\n",
    "prompt_template = \"\"\"<|system|>\n",
    "{system}\n",
    "<|user|>\n",
    "{instruction}\n",
    "<|assistant|>\n",
    "{completion}<|endoftext|>\"\"\"\n",
    "\n",
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    # Define system message\n",
    "    system_message = \"You are an AI assistant trained to summarize conversations accurately and concisely.\"\n",
    "    \n",
    "    # Format the instruction using the dialogue\n",
    "    instruction = f\"Summarize the following conversation:\\n\\n{sample['dialogue']}\"\n",
    "    \n",
    "    # Use the summary as the completion\n",
    "    completion = sample['summary']\n",
    "    \n",
    "    # Create the formatted text\n",
    "    sample[\"text\"] = prompt_template.format(\n",
    "        system=system_message,\n",
    "        instruction=instruction,\n",
    "        completion=completion\n",
    "    )\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T00:02:10.364459Z",
     "start_time": "2023-09-03T00:02:09.672705Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d7f096b3e44f629187ac7b8571d908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are an AI assistant trained to summarize conversations accurately and concisely.\n",
      "<|user|>\n",
      "Summarize the following conversation:\n",
      "\n",
      "Ben: Rafal, how are you?\n",
      "Rafal: Awesome, getting ready for the evening:D\n",
      "Ben: In 2h and 30min, we can meet up:)\n",
      "Ben: Cool\n",
      "Rafal: Yee\n",
      "Ben: Which subway exit is comfortable for you?\n",
      "Rafal: All are fine, I haven't been there yet. Do you have any preferences?\n",
      "Ben: I heaard that from exit 9 there are lots of restaurants, look at the map\n",
      "Ben: <file_picture>\n",
      "Ben: Which line are you supposed to take?\n",
      "Rafal: I take blue line, so exit 9 will be perfect\n",
      "Ben: good then I will be there\n",
      "Rafal: Perfect, see you soon! \n",
      "Ben: Ah and if I arrive there I will contact your wife\n",
      "Ben: If you have something trouble\n",
      "Ben: can you send me text message 0123456789\n",
      "Ben: I don't have any data left, hahhah\n",
      "<|assistant|>\n",
      "Ben and Rafal are meeting in 2.5 hours at the subway exit 9.<|endoftext|>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caeff0c5aed3477eb5b76682734f0fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "\n",
    "dataset = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
    "\n",
    "train_dataset = dataset[\"train\"].map(template_dataset, remove_columns=list(dataset[\"train\"].features))\n",
    "\n",
    "print(train_dataset[randint(0, len(dataset))][\"text\"])\n",
    "\n",
    "test_dataset = dataset[\"test\"].map(template_dataset, remove_columns=list(dataset[\"test\"].features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function for initializing the distribution across multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def init_distributed():\n",
    "    # Initialize the process group\n",
    "    torch.distributed.init_process_group(\n",
    "        backend=\"nccl\", # Use \"gloo\" backend for CPU\n",
    "        timeout=datetime.timedelta(seconds=5400)\n",
    "    )\n",
    "    local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "    torch.cuda.set_device(local_rank)\n",
    "\n",
    "    return local_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function for model download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "import os\n",
    "\n",
    "def download_model(model_name):\n",
    "    print(\"Downloading model \", model_name)\n",
    "\n",
    "    os.makedirs(\"/tmp/tmp_folder\", exist_ok=True)\n",
    "\n",
    "    snapshot_download(repo_id=model_name, local_dir=\"/tmp/tmp_folder\")\n",
    "\n",
    "    print(f\"Model {model_name} downloaded under /tmp/tmp_folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Hugging Face Trainer class to fine-tune the model. Define the hyperparameters we want to use. We also create a DataCollator that will take care of padding our inputs and labels. To train our model, we need to convert our inputs (text) to token IDs. This is done by a Hugging Face Transformers Tokenizer. In addition to Lora, we will use bitsanbytes 4-bit precision to quantize out frozen LLM to 4-bit and attach LoRA adapters on it.\n",
    "\n",
    "Define the train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/06/25 20:55:02] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/06/25 20:55:02]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=187788;file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=580087;file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.ImageUri\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.Dependencies\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.PreExecutionCommands\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.IncludeLocalWorkDir\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.CustomFileFilter.IgnoreNamePatterns\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.InstanceType\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "import datetime\n",
    "import os\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from sagemaker.remote_function import remote\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, set_seed\n",
    "import transformers\n",
    "import traceback\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# Start training\n",
    "@remote(\n",
    "    keep_alive_period_in_seconds=0, #Warm-pool instance. Put 0 for avoiding additional costs\n",
    "    volume_size=100,\n",
    "    job_name_prefix=f\"train-{model_id.split('/')[-1].replace('.', '-')}\",\n",
    "    use_torchrun=True,\n",
    ")\n",
    "def train_fn(\n",
    "    model_name,             # Name or path of the base model to fine-tune\n",
    "    train_ds,               # Training dataset\n",
    "    test_ds=None,           # Optional test/validation dataset\n",
    "    torch_dtype=torch.bfloat16,  # Precision type for training\n",
    "    lora_r=8,               # LoRA rank - controls capacity of adaptations\n",
    "    lora_alpha=16,          # LoRA alpha - scales the adaptations\n",
    "    lora_dropout=0.1,       # Dropout probability for LoRA layers\n",
    "    per_device_train_batch_size=8,  # Batch size for training\n",
    "    per_device_eval_batch_size=8,   # Batch size for evaluation\n",
    "    gradient_accumulation_steps=1,  # Number of steps to accumulate gradients\n",
    "    learning_rate=2e-4,     # Learning rate for training\n",
    "    num_train_epochs=1,     # Number of training epochs\n",
    "    fsdp=\"\",                # Fully Sharded Data Parallel configuration\n",
    "    fsdp_config=None,       # Additional FSDP configurations\n",
    "    gradient_checkpointing=False,  # Whether to use gradient checkpointing\n",
    "    merge_weights=False,    # Whether to merge LoRA weights with base model\n",
    "    seed=42,                # Random seed for reproducibility\n",
    "    mlflow_uri=None,\n",
    "    mlflow_experiment_name=None,\n",
    "    token='<>'              # HuggingFace token for model access\n",
    "):\n",
    "    # Initialize distributed training if multiple GPUs are available\n",
    "    if torch.cuda.is_available() and (torch.cuda.device_count() > 1 or int(os.environ.get(\"SM_HOST_COUNT\", 1)) > 1):\n",
    "        # Call this function at the beginning of your script\n",
    "        local_rank = init_distributed()\n",
    "\n",
    "        # Now you can use distributed functionalities\n",
    "        torch.distributed.barrier(device_ids=[local_rank])\n",
    "\n",
    "    # Enable HuggingFace transfer for model downloading\n",
    "    os.environ.update({\"HF_HUB_ENABLE_HF_TRANSFER\": \"1\"})\n",
    "\n",
    "    set_seed(seed)\n",
    "\n",
    "    accelerator = Accelerator()\n",
    "\n",
    "    # Set up HuggingFace token if provided\n",
    "    if token is not None:\n",
    "        os.environ.update({\"HF_TOKEN\": token})\n",
    "        accelerator.wait_for_everyone()\n",
    "\n",
    "    # Download model based on training setup (single or multi-node)\n",
    "    if int(os.environ.get(\"SM_HOST_COUNT\", 1)) == 1:\n",
    "        if accelerator.is_main_process:\n",
    "            download_model(model_name)\n",
    "    else:\n",
    "        download_model(model_name)\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "\n",
    "    model_name = \"/tmp/tmp_folder\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Set Tokenizer pad Token\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        # tokenize and chunk dataset\n",
    "        lm_train_dataset = train_ds.map(\n",
    "            lambda sample: tokenizer(sample[\"text\"]), remove_columns=list(train_ds.features)\n",
    "        )\n",
    "\n",
    "        print(f\"Total number of train samples: {len(lm_train_dataset)}\")\n",
    "\n",
    "        if test_ds is not None:\n",
    "            lm_test_dataset = test_ds.map(\n",
    "                lambda sample: tokenizer(sample[\"text\"]), remove_columns=list(test_ds.features)\n",
    "            )\n",
    "\n",
    "            print(f\"Total number of test samples: {len(lm_test_dataset)}\")\n",
    "        else:\n",
    "            lm_test_dataset = None\n",
    "\n",
    "    # Configure model settings for bfloat16 precision\n",
    "    # Setup flash_attention_2 for memory-efficient attention computation\n",
    "    if torch_dtype == torch.bfloat16:\n",
    "        print(\"flash_attention_2 init\")\n",
    "\n",
    "        model_configs = {\n",
    "            \"attn_implementation\": \"flash_attention_2\",\n",
    "            \"torch_dtype\": torch_dtype,\n",
    "        }\n",
    "    else:\n",
    "        model_configs = dict()\n",
    "\n",
    "    # Configure training settings based on FSDP usage\n",
    "    # Set up trainer configurations for FSDP or standard training\n",
    "    if fsdp != \"\" and fsdp_config is not None:\n",
    "        print(\"Configurations for FSDP\")\n",
    "\n",
    "        bnb_config_params = {\n",
    "            \"bnb_4bit_quant_storage\": torch_dtype\n",
    "        }\n",
    "\n",
    "        trainer_configs = {\n",
    "            \"fsdp\": fsdp,\n",
    "            \"fsdp_config\": fsdp_config,\n",
    "            \"gradient_checkpointing_kwargs\": {\n",
    "                \"use_reentrant\": False\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        bnb_config_params = dict()\n",
    "        trainer_configs = {\n",
    "            \"gradient_checkpointing\": gradient_checkpointing, # Enable in case of DDP\n",
    "        }\n",
    "\n",
    "    # Enable Quantization\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch_dtype,\n",
    "        **bnb_config_params\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        quantization_config=bnb_config,\n",
    "        use_cache=not gradient_checkpointing,\n",
    "        cache_dir=\"/tmp/.cache\",\n",
    "        **model_configs\n",
    "    )\n",
    "\n",
    "    # Configure gradient checkpointing based on FSDP usage\n",
    "    if fsdp == \"\" and fsdp_config is None:\n",
    "        print(\"Prepare model for quantization\")\n",
    "        model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=gradient_checkpointing)\n",
    "\n",
    "        if gradient_checkpointing:\n",
    "            print(\"gradient_checkpointing enabled\")\n",
    "            model.gradient_checkpointing_enable()\n",
    "    else:\n",
    "        if gradient_checkpointing:\n",
    "            print(\"gradient_checkpointing enabled\")\n",
    "            model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
    "\n",
    "    config = LoraConfig(\n",
    "        r=lora_r,\n",
    "        lora_alpha=lora_alpha,\n",
    "        target_modules=\"all-linear\",\n",
    "        lora_dropout=lora_dropout,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\"\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(model, config)\n",
    "\n",
    "    trainer = transformers.Trainer(\n",
    "        model=model,\n",
    "        train_dataset=lm_train_dataset,\n",
    "        eval_dataset=lm_test_dataset if lm_test_dataset is not None else None,\n",
    "        args=transformers.TrainingArguments(\n",
    "            per_device_train_batch_size=per_device_train_batch_size,\n",
    "            per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "            gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "            logging_strategy=\"steps\",\n",
    "            logging_steps=1,\n",
    "            log_on_each_node=False,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            learning_rate=learning_rate,\n",
    "            bf16=(\n",
    "                True if torch_dtype == torch.bfloat16 else False\n",
    "            ),  # Enable mixed-precision training\n",
    "            tf32=False,\n",
    "            ddp_find_unused_parameters=False,\n",
    "            save_strategy=\"no\",\n",
    "            output_dir=\"outputs\",\n",
    "            **trainer_configs\n",
    "        ),\n",
    "        data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    )\n",
    "\n",
    "    if trainer.accelerator.is_main_process:\n",
    "        trainer.model.print_trainable_parameters()\n",
    "        \n",
    "    if mlflow_uri is not None and mlflow_experiment_name is not None:\n",
    "        print(\"MLflow tracking under \", mlflow_experiment_name)\n",
    "        # Logs for experiments\n",
    "        modules = find_all_linear_names(model)\n",
    "\n",
    "        mlflow.set_tracking_uri(mlflow_uri)\n",
    "        mlflow.set_experiment(mlflow_experiment_name)\n",
    "\n",
    "        with mlflow.start_run(run_name=f\"Training\") as run:\n",
    "            lora_params = {\n",
    "                \"lora_alpha\": lora_alpha,\n",
    "                \"lora_dropout\": lora_dropout,\n",
    "                \"r\": lora_r,\n",
    "                \"modules\": modules\n",
    "            }\n",
    "\n",
    "            mlflow.log_params(lora_params)\n",
    "\n",
    "            trainer.train()\n",
    "    else:\n",
    "        trainer.train()\n",
    "\n",
    "    if trainer.is_fsdp_enabled:\n",
    "        trainer.accelerator.state.fsdp_plugin.set_state_dict_type(\"FULL_STATE_DICT\")\n",
    "\n",
    "    if merge_weights:\n",
    "        output_dir = \"/tmp/model\"\n",
    "\n",
    "        # merge adapter weights with base model and save\n",
    "        # save int 4 model\n",
    "        trainer.model.save_pretrained(output_dir, safe_serialization=False)\n",
    "\n",
    "        if accelerator.is_main_process:\n",
    "            # clear memory\n",
    "            del model\n",
    "            del trainer\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # load PEFT model\n",
    "            model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "                output_dir,\n",
    "                torch_dtype=torch.float16,\n",
    "                low_cpu_mem_usage=True,\n",
    "                trust_remote_code=True,\n",
    "                use_cache=True,\n",
    "                cache_dir=\"/tmp/.cache\",\n",
    "            )\n",
    "\n",
    "            # Merge LoRA and base model and save\n",
    "            model = model.merge_and_unload()\n",
    "            model.save_pretrained(\n",
    "                os.environ.get(\"SM_MODEL_DIR\", \"/opt/ml/model\"),\n",
    "                safe_serialization=True,\n",
    "                max_shard_size=\"2GB\"\n",
    "            )\n",
    "    else:\n",
    "        trainer.model.save_pretrained(\n",
    "            os.environ.get(\"SM_MODEL_DIR\", \"/opt/ml/model\"),\n",
    "            safe_serialization=True\n",
    "        )\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(os.environ.get(\"SM_MODEL_DIR\", \"/opt/ml/model\"))\n",
    "        \n",
    "         # Model registration in MLFlow\n",
    "        if mlflow_uri is not None and mlflow_experiment_name is not None:\n",
    "            print(\"MLflow model registration under \", mlflow_experiment_name)\n",
    "\n",
    "            params = {\n",
    "                \"top_p\": 0.9,\n",
    "                \"temperature\": 0.2,\n",
    "                \"max_new_tokens\": 2048,\n",
    "            }\n",
    "            signature = infer_signature(\"inputs\", \"generated_text\", params=params)\n",
    "\n",
    "            mlflow.transformers.log_model(\n",
    "                transformers_model={\"model\": model, \"tokenizer\": tokenizer},\n",
    "                signature=signature,\n",
    "                artifact_path=\"model\",  # This is a relative path to save model files within MLflow run\n",
    "                model_config=params,\n",
    "                task=\"text-generation\"\n",
    "            )\n",
    "\n",
    "    accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Run train_fn with merge_weights=True for merging the trained adapter. **Update HF_TOKEN with your HuggingFace access token**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 20:55:17,856 sagemaker.remote_function INFO     Serializing function code to s3://sagemaker-us-east-1-058264176820/train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856/function\n",
      "2025-04-06 20:55:17,970 sagemaker.remote_function INFO     Serializing function arguments to s3://sagemaker-us-east-1-058264176820/train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856/arguments\n",
      "2025-04-06 20:55:18,305 sagemaker.remote_function INFO     Copied user workspace to '/tmp/tmpji8d_ps3/temp_workspace/sagemaker_remote_function_workspace'\n",
      "2025-04-06 20:55:18,307 sagemaker.remote_function INFO     Copied dependencies file at './requirements.txt' to '/tmp/tmpji8d_ps3/temp_workspace/sagemaker_remote_function_workspace/requirements.txt'\n",
      "2025-04-06 20:55:18,308 sagemaker.remote_function INFO     Generated pre-execution script from commands to '/tmp/tmpji8d_ps3/temp_workspace/sagemaker_remote_function_workspace/pre_exec.sh'\n",
      "2025-04-06 20:55:18,309 sagemaker.remote_function INFO     Successfully created workdir archive at '/tmp/tmpji8d_ps3/workspace.zip'\n",
      "2025-04-06 20:55:18,335 sagemaker.remote_function INFO     Successfully uploaded workdir to 's3://sagemaker-us-east-1-058264176820/train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856/sm_rf_user_ws/workspace.zip'\n",
      "2025-04-06 20:55:18,336 sagemaker.remote_function INFO     Creating job: train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-06 20:55:22 Starting - Starting the training job\n",
      "...........20:55:22 Pending - Training job waiting for capacity.\n",
      ".....04-06 20:57:23 Pending - Preparing the instances for training.\n",
      "....................Downloading - Downloading the training image.\n",
      "..\u001b[34mINFO: CONDA_PKGS_DIRS is set to '/opt/ml/sagemaker/warmpoolcache/sm_remotefunction_user_dependencies_cache/conda/pkgs'\u001b[0m\n",
      "\u001b[34mINFO: PIP_CACHE_DIR is set to '/opt/ml/sagemaker/warmpoolcache/sm_remotefunction_user_dependencies_cache/pip'\u001b[0m\n",
      "\u001b[34mINFO: /opt/ml/input/config/resourceconfig.json:\u001b[0m\n",
      "\u001b[34m{\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.12xlarge\",\"current_group_name\":\"homogeneousCluster\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\",\"hosts\":[\"algo-1\"]}],\"network_interface_name\":\"eth0\"}INFO: Bootstraping runtime environment.\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:17,500 sagemaker.remote_function INFO     Arguments:\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:17,500 sagemaker.remote_function INFO     job_conda_env=None\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:17,500 sagemaker.remote_function INFO     client_python_version=3.11\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:17,500 sagemaker.remote_function INFO     client_sagemaker_pysdk_version=2.239.3\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:17,500 sagemaker.remote_function INFO     pipeline_execution_id=None\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:17,500 sagemaker.remote_function INFO     dependency_settings={\"dependency_file\": \"requirements.txt\"}\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:17,500 sagemaker.remote_function INFO     func_step_s3_dir=None\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:17,500 sagemaker.remote_function INFO     distribution=torchrun\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:17,500 sagemaker.remote_function INFO     user_nproc_per_node=None\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:17,502 sagemaker.remote_function INFO     Successfully unpacked workspace archive at '/'.\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:17,502 sagemaker.remote_function INFO     Running pre-execution commands in '/sagemaker_remote_function_workspace/pre_exec.sh'\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:17,504 sagemaker.remote_function INFO     Running command: '/opt/conda/bin/python -m pip install -r /sagemaker_remote_function_workspace/requirements.txt -U' in the dir: '/' \u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:17,899 sagemaker.remote_function INFO     Collecting transformers==4.48.2 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:17,929 sagemaker.remote_function INFO       Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,021 sagemaker.remote_function INFO     Collecting peft==0.14.0 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,027 sagemaker.remote_function INFO       Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,048 sagemaker.remote_function INFO     Collecting accelerate==1.3.0 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,056 sagemaker.remote_function INFO       Downloading accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,078 sagemaker.remote_function INFO     Collecting bitsandbytes==0.45.1 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,083 sagemaker.remote_function INFO       Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,106 sagemaker.remote_function INFO     Collecting datasets==3.2.0 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,110 sagemaker.remote_function INFO       Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,144 sagemaker.remote_function INFO     Collecting evaluate==0.4.3 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,147 sagemaker.remote_function INFO       Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,179 sagemaker.remote_function INFO     Collecting mlflow (from -r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,183 sagemaker.remote_function INFO       Downloading mlflow-2.21.3-py3-none-any.whl.metadata (30 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,194 sagemaker.remote_function INFO     Requirement already satisfied: safetensors>=0.5.2 in /opt/conda/lib/python3.11/site-packages (from -r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (0.5.3)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,317 sagemaker.remote_function INFO     Collecting sagemaker==2.239.3 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,321 sagemaker.remote_function INFO       Downloading sagemaker-2.239.3-py3-none-any.whl.metadata (16 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,344 sagemaker.remote_function INFO     Collecting sagemaker-mlflow==0.1.0 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 11))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,347 sagemaker.remote_function INFO       Downloading sagemaker_mlflow-0.1.0-py3-none-any.whl.metadata (3.3 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,381 sagemaker.remote_function INFO     Collecting sentencepiece==0.2.0 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 12))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,385 sagemaker.remote_function INFO       Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,388 sagemaker.remote_function INFO     Requirement already satisfied: scikit-learn==1.6.1 in /opt/conda/lib/python3.11/site-packages (from -r /sagemaker_remote_function_workspace/requirements.txt (line 13)) (1.6.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,571 sagemaker.remote_function INFO     Collecting tokenizers>=0.21.0 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,576 sagemaker.remote_function INFO       Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,602 sagemaker.remote_function INFO     Collecting py7zr (from -r /sagemaker_remote_function_workspace/requirements.txt (line 15))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,634 sagemaker.remote_function INFO       Downloading py7zr-0.22.0-py3-none-any.whl.metadata (16 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,645 sagemaker.remote_function INFO     Requirement already satisfied: huggingface_hub[hf_transfer] in /opt/conda/lib/python3.11/site-packages (from -r /sagemaker_remote_function_workspace/requirements.txt (line 7)) (0.29.3)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,669 sagemaker.remote_function INFO     Collecting huggingface_hub[hf_transfer] (from -r /sagemaker_remote_function_workspace/requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,672 sagemaker.remote_function INFO       Downloading huggingface_hub-0.30.1-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,689 sagemaker.remote_function INFO     Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers==4.48.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (3.17.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,690 sagemaker.remote_function INFO     Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.48.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (1.26.4)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,690 sagemaker.remote_function INFO     Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers==4.48.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (24.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,690 sagemaker.remote_function INFO     Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.48.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (6.0.2)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,913 sagemaker.remote_function INFO     Collecting regex!=2019.12.17 (from transformers==4.48.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,916 sagemaker.remote_function INFO       Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,922 sagemaker.remote_function INFO     Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers==4.48.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (2.32.3)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,926 sagemaker.remote_function INFO     Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers==4.48.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (4.66.5)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,928 sagemaker.remote_function INFO     Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft==0.14.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (7.0.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,928 sagemaker.remote_function INFO     Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from peft==0.14.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (2.5.1+cu124)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,940 sagemaker.remote_function INFO     Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets==3.2.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5)) (19.0.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,949 sagemaker.remote_function INFO     Collecting dill<0.3.9,>=0.3.0 (from datasets==3.2.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,952 sagemaker.remote_function INFO       Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:18,956 sagemaker.remote_function INFO     Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets==3.2.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5)) (2.2.3)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,030 sagemaker.remote_function INFO     Collecting xxhash (from datasets==3.2.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,035 sagemaker.remote_function INFO       Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,051 sagemaker.remote_function INFO     Collecting multiprocess<0.70.17 (from datasets==3.2.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,054 sagemaker.remote_function INFO       Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,073 sagemaker.remote_function INFO     Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.2.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,076 sagemaker.remote_function INFO       Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,367 sagemaker.remote_function INFO     Collecting aiohttp (from datasets==3.2.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,371 sagemaker.remote_function INFO       Downloading aiohttp-3.11.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,390 sagemaker.remote_function INFO     Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (23.2.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,390 sagemaker.remote_function INFO     Requirement already satisfied: boto3<2.0,>=1.35.75 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (1.37.11)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,390 sagemaker.remote_function INFO     Requirement already satisfied: cloudpickle>=2.2.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (2.2.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,390 sagemaker.remote_function INFO     Requirement already satisfied: docker in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (7.1.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,391 sagemaker.remote_function INFO     Requirement already satisfied: fastapi in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (0.115.11)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,391 sagemaker.remote_function INFO     Requirement already satisfied: google-pasta in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (0.2.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,391 sagemaker.remote_function INFO     Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (6.11.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,392 sagemaker.remote_function INFO     Requirement already satisfied: jsonschema in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (4.23.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,392 sagemaker.remote_function INFO     Requirement already satisfied: omegaconf<=2.3,>=2.2 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (2.3.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,392 sagemaker.remote_function INFO     Requirement already satisfied: pathos in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (0.3.3)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,393 sagemaker.remote_function INFO     Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (4.3.6)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,393 sagemaker.remote_function INFO     Requirement already satisfied: protobuf<6.0,>=3.12 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (3.20.3)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,394 sagemaker.remote_function INFO     Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.17 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (1.0.25)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,394 sagemaker.remote_function INFO     Requirement already satisfied: schema in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (0.7.7)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,394 sagemaker.remote_function INFO     Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (1.0.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,395 sagemaker.remote_function INFO     Requirement already satisfied: tblib<4,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (3.0.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,395 sagemaker.remote_function INFO     Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (1.26.19)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,395 sagemaker.remote_function INFO     Requirement already satisfied: uvicorn in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (0.34.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,410 sagemaker.remote_function INFO     Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.6.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 13)) (1.15.2)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,440 sagemaker.remote_function INFO     Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.6.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 13)) (1.4.2)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,440 sagemaker.remote_function INFO     Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.6.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 13)) (3.6.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,450 sagemaker.remote_function INFO     Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[hf_transfer]->-r /sagemaker_remote_function_workspace/requirements.txt (line 7)) (4.12.2)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,475 sagemaker.remote_function INFO     Collecting hf-transfer>=0.1.4 (from huggingface_hub[hf_transfer]->-r /sagemaker_remote_function_workspace/requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,479 sagemaker.remote_function INFO       Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,501 sagemaker.remote_function INFO     Collecting mlflow-skinny==2.21.3 (from mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,505 sagemaker.remote_function INFO       Downloading mlflow_skinny-2.21.3-py3-none-any.whl.metadata (31 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,526 sagemaker.remote_function INFO     Collecting Flask<4 (from mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,529 sagemaker.remote_function INFO       Downloading flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,532 sagemaker.remote_function INFO     Requirement already satisfied: Jinja2<4,>=2.11 in /opt/conda/lib/python3.11/site-packages (from mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (3.1.6)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,551 sagemaker.remote_function INFO     Collecting alembic!=1.10.0,<2 (from mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,554 sagemaker.remote_function INFO       Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,591 sagemaker.remote_function INFO     Collecting graphene<4 (from mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,611 sagemaker.remote_function INFO       Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,631 sagemaker.remote_function INFO     Collecting gunicorn<24 (from mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,634 sagemaker.remote_function INFO       Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,638 sagemaker.remote_function INFO     Requirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.11/site-packages (from mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (3.7)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,639 sagemaker.remote_function INFO     Requirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.11/site-packages (from mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (3.10.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,828 sagemaker.remote_function INFO     Collecting sqlalchemy<3,>=1.4.0 (from mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,832 sagemaker.remote_function INFO       Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,856 sagemaker.remote_function INFO     Collecting cachetools<6,>=5.0.0 (from mlflow-skinny==2.21.3->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,859 sagemaker.remote_function INFO       Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,862 sagemaker.remote_function INFO     Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.21.3->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (8.1.8)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,892 sagemaker.remote_function INFO     Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.21.3->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,895 sagemaker.remote_function INFO       Downloading databricks_sdk-0.49.0-py3-none-any.whl.metadata (38 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,922 sagemaker.remote_function INFO     Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==2.21.3->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,925 sagemaker.remote_function INFO       Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,946 sagemaker.remote_function INFO     Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.21.3->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,949 sagemaker.remote_function INFO       Downloading opentelemetry_api-1.31.1-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,966 sagemaker.remote_function INFO     Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.21.3->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,971 sagemaker.remote_function INFO       Downloading opentelemetry_sdk-1.31.1-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,974 sagemaker.remote_function INFO     Requirement already satisfied: pydantic<3,>=1.10.8 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.21.3->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (2.10.6)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,984 sagemaker.remote_function INFO     Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.21.3->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:19,988 sagemaker.remote_function INFO       Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,005 sagemaker.remote_function INFO     Collecting texttable (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 15))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,008 sagemaker.remote_function INFO       Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,064 sagemaker.remote_function INFO     Collecting pycryptodomex>=3.16.0 (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 15))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,068 sagemaker.remote_function INFO       Downloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,165 sagemaker.remote_function INFO     Collecting pyzstd>=0.15.9 (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 15))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,181 sagemaker.remote_function INFO       Downloading pyzstd-0.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,232 sagemaker.remote_function INFO     Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 15))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,237 sagemaker.remote_function INFO       Downloading pyppmd-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,267 sagemaker.remote_function INFO     Collecting pybcj<1.1.0,>=1.0.0 (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 15))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,274 sagemaker.remote_function INFO       Downloading pybcj-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,286 sagemaker.remote_function INFO     Collecting multivolumefile>=0.2.3 (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 15))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,291 sagemaker.remote_function INFO       Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,322 sagemaker.remote_function INFO     Collecting inflate64<1.1.0,>=1.0.0 (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 15))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,326 sagemaker.remote_function INFO       Downloading inflate64-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,329 sagemaker.remote_function INFO     Requirement already satisfied: brotli>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 15)) (1.1.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,342 sagemaker.remote_function INFO     Collecting Mako (from alembic!=1.10.0,<2->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,347 sagemaker.remote_function INFO       Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,354 sagemaker.remote_function INFO     Requirement already satisfied: botocore<1.38.0,>=1.37.11 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.35.75->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (1.37.11)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,354 sagemaker.remote_function INFO     Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.35.75->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (1.0.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,355 sagemaker.remote_function INFO     Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.35.75->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (0.11.4)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,364 sagemaker.remote_function INFO     Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /opt/conda/lib/python3.11/site-packages (from fastapi->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (0.46.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,366 sagemaker.remote_function INFO     Requirement already satisfied: Werkzeug>=3.1 in /opt/conda/lib/python3.11/site-packages (from Flask<4->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (3.1.3)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,375 sagemaker.remote_function INFO     Collecting itsdangerous>=2.2 (from Flask<4->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,377 sagemaker.remote_function INFO       Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,387 sagemaker.remote_function INFO     Collecting blinker>=1.9 (from Flask<4->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,391 sagemaker.remote_function INFO       Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,424 sagemaker.remote_function INFO     Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets==3.2.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,427 sagemaker.remote_function INFO       Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,435 sagemaker.remote_function INFO     Collecting aiosignal>=1.1.2 (from aiohttp->datasets==3.2.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,438 sagemaker.remote_function INFO       Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,472 sagemaker.remote_function INFO     Collecting frozenlist>=1.1.1 (from aiohttp->datasets==3.2.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,475 sagemaker.remote_function INFO       Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,592 sagemaker.remote_function INFO     Collecting multidict<7.0,>=4.5 (from aiohttp->datasets==3.2.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,609 sagemaker.remote_function INFO       Downloading multidict-6.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.1 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,639 sagemaker.remote_function INFO     Collecting propcache>=0.2.0 (from aiohttp->datasets==3.2.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,642 sagemaker.remote_function INFO       Downloading propcache-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,853 sagemaker.remote_function INFO     Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets==3.2.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,857 sagemaker.remote_function INFO       Downloading yarl-1.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (71 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,887 sagemaker.remote_function INFO     Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,890 sagemaker.remote_function INFO       Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,901 sagemaker.remote_function INFO     Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,904 sagemaker.remote_function INFO       Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,908 sagemaker.remote_function INFO     Requirement already satisfied: python-dateutil<3,>=2.7.0 in /opt/conda/lib/python3.11/site-packages (from graphene<4->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (2.9.0.post0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,917 sagemaker.remote_function INFO     Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (3.21.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,921 sagemaker.remote_function INFO     Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from Jinja2<4,>=2.11->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (3.0.2)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,927 sagemaker.remote_function INFO     Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (1.3.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,927 sagemaker.remote_function INFO     Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (0.12.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,927 sagemaker.remote_function INFO     Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (4.56.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,928 sagemaker.remote_function INFO     Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (1.4.7)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,928 sagemaker.remote_function INFO     Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (11.1.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,929 sagemaker.remote_function INFO     Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (3.2.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,937 sagemaker.remote_function INFO     Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/conda/lib/python3.11/site-packages (from omegaconf<=2.3,>=2.2->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (4.9.3)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,951 sagemaker.remote_function INFO     Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==3.2.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5)) (2024.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,951 sagemaker.remote_function INFO     Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==3.2.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5)) (2025.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,969 sagemaker.remote_function INFO     Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.48.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (3.4.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,969 sagemaker.remote_function INFO     Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.48.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (3.10)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,970 sagemaker.remote_function INFO     Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.48.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (2025.1.31)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,974 sagemaker.remote_function INFO     Requirement already satisfied: rich<14.0.0,>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (13.9.4)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,974 sagemaker.remote_function INFO     Requirement already satisfied: mock<5.0,>4.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (4.0.3)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,978 sagemaker.remote_function INFO     Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (2024.10.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,979 sagemaker.remote_function INFO     Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (0.36.2)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,979 sagemaker.remote_function INFO     Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (0.23.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,989 sagemaker.remote_function INFO     Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy<3,>=1.4.0->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (3.1.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,997 sagemaker.remote_function INFO     Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.14.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (3.4.2)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:20,997 sagemaker.remote_function INFO     Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.14.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (1.13.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,000 sagemaker.remote_function INFO     Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.14.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (1.3.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,012 sagemaker.remote_function INFO     Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.11/site-packages (from uvicorn->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (0.14.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,018 sagemaker.remote_function INFO     Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from google-pasta->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (1.17.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,020 sagemaker.remote_function INFO     Requirement already satisfied: ppft>=1.7.6.9 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (1.7.6.9)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,022 sagemaker.remote_function INFO     INFO: pip is looking at multiple versions of pathos to determine which version is compatible with other requirements. This could take a while.\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,029 sagemaker.remote_function INFO     Collecting pathos (from sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,032 sagemaker.remote_function INFO       Downloading pathos-0.3.2-py3-none-any.whl.metadata (11 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,036 sagemaker.remote_function INFO     Requirement already satisfied: pox>=0.3.4 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (0.3.5)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,111 sagemaker.remote_function INFO     Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,115 sagemaker.remote_function INFO       Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,139 sagemaker.remote_function INFO     Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==2.21.3->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,141 sagemaker.remote_function INFO       Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,188 sagemaker.remote_function INFO     Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,191 sagemaker.remote_function INFO       Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,210 sagemaker.remote_function INFO     Collecting opentelemetry-semantic-conventions==0.52b1 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,214 sagemaker.remote_function INFO       Downloading opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl.metadata (2.5 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,234 sagemaker.remote_function INFO     Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (0.7.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,234 sagemaker.remote_function INFO     Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (2.27.2)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,250 sagemaker.remote_function INFO     Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (3.0.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,250 sagemaker.remote_function INFO     Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (2.19.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,263 sagemaker.remote_function INFO     Requirement already satisfied: anyio<5,>=3.6.2 in /opt/conda/lib/python3.11/site-packages (from starlette<0.47.0,>=0.40.0->fastapi->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (4.8.0)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,294 sagemaker.remote_function INFO     Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (1.3.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,296 sagemaker.remote_function INFO     Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (1.17.2)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,309 sagemaker.remote_function INFO     Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.21.3->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,313 sagemaker.remote_function INFO       Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,335 sagemaker.remote_function INFO     Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,338 sagemaker.remote_function INFO       Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,340 sagemaker.remote_function INFO     Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (4.7.2)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,346 sagemaker.remote_function INFO     Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker==2.239.3->-r /sagemaker_remote_function_workspace/requirements.txt (line 10)) (0.1.2)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,356 sagemaker.remote_function INFO     Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow->-r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (0.6.1)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,384 sagemaker.remote_function INFO     Downloading transformers-4.48.2-py3-none-any.whl (9.7 MB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,503 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.7/9.7 MB 81.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,508 sagemaker.remote_function INFO     Downloading peft-0.14.0-py3-none-any.whl (374 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,518 sagemaker.remote_function INFO     Downloading accelerate-1.3.0-py3-none-any.whl (336 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:21,526 sagemaker.remote_function INFO     Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,568 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 69.7/69.7 MB 66.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,577 sagemaker.remote_function INFO     Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,584 sagemaker.remote_function INFO     Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,602 sagemaker.remote_function INFO     Downloading sagemaker-2.239.3-py3-none-any.whl (1.6 MB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,616 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 119.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,620 sagemaker.remote_function INFO     Downloading sagemaker_mlflow-0.1.0-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,631 sagemaker.remote_function INFO     Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,647 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 82.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,650 sagemaker.remote_function INFO     Downloading mlflow-2.21.3-py3-none-any.whl (28.2 MB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,840 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 28.2/28.2 MB 150.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,843 sagemaker.remote_function INFO     Downloading mlflow_skinny-2.21.3-py3-none-any.whl (6.1 MB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,886 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.1/6.1 MB 150.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,890 sagemaker.remote_function INFO     Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,909 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 172.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,913 sagemaker.remote_function INFO     Downloading py7zr-0.22.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,918 sagemaker.remote_function INFO     Downloading alembic-1.15.2-py3-none-any.whl (231 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,923 sagemaker.remote_function INFO     Downloading dill-0.3.8-py3-none-any.whl (116 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,928 sagemaker.remote_function INFO     Downloading flask-3.1.0-py3-none-any.whl (102 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,933 sagemaker.remote_function INFO     Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,940 sagemaker.remote_function INFO     Downloading aiohttp-3.11.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,952 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 151.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,959 sagemaker.remote_function INFO     Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,965 sagemaker.remote_function INFO     Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:22,975 sagemaker.remote_function INFO     Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,006 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 117.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,009 sagemaker.remote_function INFO     Downloading huggingface_hub-0.30.1-py3-none-any.whl (481 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,035 sagemaker.remote_function INFO     Downloading inflate64-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (96 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,040 sagemaker.remote_function INFO     Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,047 sagemaker.remote_function INFO     Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,054 sagemaker.remote_function INFO     Downloading pybcj-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,058 sagemaker.remote_function INFO     Downloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,072 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 176.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,076 sagemaker.remote_function INFO     Downloading pyppmd-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,082 sagemaker.remote_function INFO     Downloading pyzstd-0.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,090 sagemaker.remote_function INFO     Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,097 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 792.7/792.7 kB 118.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,099 sagemaker.remote_function INFO     Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,131 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 104.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,136 sagemaker.remote_function INFO     Downloading pathos-0.3.2-py3-none-any.whl (82 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,141 sagemaker.remote_function INFO     Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,146 sagemaker.remote_function INFO     Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,152 sagemaker.remote_function INFO     Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,156 sagemaker.remote_function INFO     Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,161 sagemaker.remote_function INFO     Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,165 sagemaker.remote_function INFO     Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,170 sagemaker.remote_function INFO     Downloading databricks_sdk-0.49.0-py3-none-any.whl (683 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,177 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 684.0/684.0 kB 109.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,181 sagemaker.remote_function INFO     Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,187 sagemaker.remote_function INFO     Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,193 sagemaker.remote_function INFO     Downloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,199 sagemaker.remote_function INFO     Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,203 sagemaker.remote_function INFO     Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,208 sagemaker.remote_function INFO     Downloading multidict-6.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (238 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,214 sagemaker.remote_function INFO     Downloading opentelemetry_api-1.31.1-py3-none-any.whl (65 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,219 sagemaker.remote_function INFO     Downloading opentelemetry_sdk-1.31.1-py3-none-any.whl (118 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,224 sagemaker.remote_function INFO     Downloading opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl (183 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,230 sagemaker.remote_function INFO     Downloading propcache-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (232 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,236 sagemaker.remote_function INFO     Downloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,241 sagemaker.remote_function INFO     Downloading yarl-1.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (358 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,247 sagemaker.remote_function INFO     Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,256 sagemaker.remote_function INFO     Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,261 sagemaker.remote_function INFO     Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,267 sagemaker.remote_function INFO     Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,272 sagemaker.remote_function INFO     Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,278 sagemaker.remote_function INFO     Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:23,810 sagemaker.remote_function INFO     Installing collected packages: texttable, sentencepiece, xxhash, sqlparse, sqlalchemy, smmap, regex, pyzstd, pyppmd, pycryptodomex, pybcj, pyasn1-modules, propcache, multivolumefile, multidict, Mako, itsdangerous, inflate64, hf-transfer, gunicorn, graphql-core, fsspec, frozenlist, dill, deprecated, cachetools, blinker, aiohappyeyeballs, yarl, py7zr, opentelemetry-api, multiprocess, huggingface_hub, graphql-relay, google-auth, gitdb, Flask, alembic, aiosignal, tokenizers, pathos, opentelemetry-semantic-conventions, graphene, gitpython, databricks-sdk, bitsandbytes, aiohttp, accelerate, transformers, opentelemetry-sdk, peft, mlflow-skinny, datasets, sagemaker, mlflow, evaluate, sagemaker-mlflow\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:25,664 sagemaker.remote_function INFO       Attempting uninstall: fsspec\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:25,669 sagemaker.remote_function INFO         Found existing installation: fsspec 2025.3.0\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:25,675 sagemaker.remote_function INFO         Uninstalling fsspec-2025.3.0:\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:25,694 sagemaker.remote_function INFO           Successfully uninstalled fsspec-2025.3.0\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:25,816 sagemaker.remote_function INFO       Attempting uninstall: dill\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:25,820 sagemaker.remote_function INFO         Found existing installation: dill 0.3.9\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:25,825 sagemaker.remote_function INFO         Uninstalling dill-0.3.9:\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:25,844 sagemaker.remote_function INFO           Successfully uninstalled dill-0.3.9\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:26,052 sagemaker.remote_function INFO       Attempting uninstall: multiprocess\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:26,057 sagemaker.remote_function INFO         Found existing installation: multiprocess 0.70.17\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:26,063 sagemaker.remote_function INFO         Uninstalling multiprocess-0.70.17:\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:26,081 sagemaker.remote_function INFO           Successfully uninstalled multiprocess-0.70.17\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:26,184 sagemaker.remote_function INFO       Attempting uninstall: huggingface_hub\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:26,190 sagemaker.remote_function INFO         Found existing installation: huggingface-hub 0.29.3\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:26,202 sagemaker.remote_function INFO         Uninstalling huggingface-hub-0.29.3:\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:26,246 sagemaker.remote_function INFO           Successfully uninstalled huggingface-hub-0.29.3\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:26,792 sagemaker.remote_function INFO       Attempting uninstall: pathos\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:26,798 sagemaker.remote_function INFO         Found existing installation: pathos 0.3.3\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:26,803 sagemaker.remote_function INFO         Uninstalling pathos-0.3.3:\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:26,821 sagemaker.remote_function INFO           Successfully uninstalled pathos-0.3.3\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:28,702 sagemaker.remote_function INFO       Attempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:28,708 sagemaker.remote_function INFO         Found existing installation: accelerate 1.5.1\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:28,717 sagemaker.remote_function INFO         Uninstalling accelerate-1.5.1:\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:28,750 sagemaker.remote_function INFO           Successfully uninstalled accelerate-1.5.1\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:34,482 sagemaker.remote_function INFO       Attempting uninstall: sagemaker\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:34,488 sagemaker.remote_function INFO         Found existing installation: sagemaker 2.241.0\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:34,538 sagemaker.remote_function INFO         Uninstalling sagemaker-2.241.0:\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:34,739 sagemaker.remote_function INFO           Successfully uninstalled sagemaker-2.241.0\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:36,752 sagemaker.remote_function INFO     Successfully installed Flask-3.1.0 Mako-1.3.9 accelerate-1.3.0 aiohappyeyeballs-2.6.1 aiohttp-3.11.16 aiosignal-1.3.2 alembic-1.15.2 bitsandbytes-0.45.1 blinker-1.9.0 cachetools-5.5.2 databricks-sdk-0.49.0 datasets-3.2.0 deprecated-1.2.18 dill-0.3.8 evaluate-0.4.3 frozenlist-1.5.0 fsspec-2024.9.0 gitdb-4.0.12 gitpython-3.1.44 google-auth-2.38.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 hf-transfer-0.1.9 huggingface_hub-0.30.1 inflate64-1.0.1 itsdangerous-2.2.0 mlflow-2.21.3 mlflow-skinny-2.21.3 multidict-6.3.2 multiprocess-0.70.16 multivolumefile-0.2.3 opentelemetry-api-1.31.1 opentelemetry-sdk-1.31.1 opentelemetry-semantic-conventions-0.52b1 pathos-0.3.2 peft-0.14.0 propcache-0.3.1 py7zr-0.22.0 pyasn1-modules-0.4.2 pybcj-1.0.3 pycryptodomex-3.22.0 pyppmd-1.1.1 pyzstd-0.16.2 regex-2024.11.6 sagemaker-2.239.3 sagemaker-mlflow-0.1.0 sentencepiece-0.2.0 smmap-5.0.2 sqlalchemy-2.0.40 sqlparse-0.5.3 texttable-1.7.0 tokenizers-0.21.1 transformers-4.48.2 xxhash-3.5.0 yarl-1.19.0\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:37,118 sagemaker.remote_function WARNING  WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:37,118 sagemaker.remote_function INFO     Command /opt/conda/bin/python -m pip install -r /sagemaker_remote_function_workspace/requirements.txt -U ran successfully\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,722 sagemaker.remote_function INFO     Found /opt/ml/input/config/resourceconfig.json\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,779 sagemaker.remote_function INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,780 sagemaker.remote_function INFO     Distribution: torchrun\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,780 sagemaker.remote_function INFO     Environment Variables:\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,780 sagemaker.remote_function INFO     NVTE_FRAMEWORK=pytorch\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,780 sagemaker.remote_function INFO     NVIDIA_VISIBLE_DEVICES=all\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,780 sagemaker.remote_function INFO     PYTHONUNBUFFERED=1\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,780 sagemaker.remote_function INFO     AWS_CONTAINER_CREDENTIALS_RELATIVE_URI=******\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,780 sagemaker.remote_function INFO     SAGEMAKER_TRAINING_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,780 sagemaker.remote_function INFO     HOSTNAME=ip-10-0-188-67.ec2.internal\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,780 sagemaker.remote_function INFO     NVIDIA_REQUIRE_CUDA=cuda>=12.4 brand=tesla,driver>=470,driver<471 brand=unknown,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=geforce,driver>=470,driver<471 brand=geforcertx,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=titan,driver>=470,driver<471 brand=titanrtx,driver>=470,driver<471 brand=tesla,driver>=525,driver<526 brand=unknown,driver>=525,driver<526 brand=nvidia,driver>=525,driver<526 brand=nvidiartx,driver>=525,driver<526 brand=geforce,driver>=525,driver<526 brand=geforcertx,driver>=525,driver<526 brand=quadro,driver>=525,driver<526 brand=quadrortx,driver>=525,driver<526 brand=titan,driver>=525,driver<526 brand=titanrtx,driver>=525,driver<526 brand=tesla,driver>=535,driver<536 brand=unknown,driver>=535,driver<536 brand=nvidia,driver>=535,driver<536 brand=nvidiartx,driver>=535,driver<536 brand=geforce,driver>=535,driver<536 brand=geforcertx,driver>=535,driver<536 brand=quadro,driver>=535,driver<536 brand=quadrortx,driver>=535,driver<536 brand=titan,driver>=535,driver<536 brand=titanrtx,driver>=535,driver<536\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,780 sagemaker.remote_function INFO     TORCH_NVCC_FLAGS=-Xfatbin -compress-all\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,780 sagemaker.remote_function INFO     AWS_DEFAULT_REGION=us-east-1\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,780 sagemaker.remote_function INFO     TORCH_CUDA_ARCH_LIST=5.2;7.0+PTX;7.5;8.0;8.6;9.0\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,780 sagemaker.remote_function INFO     AWS_REGION=us-east-1\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,780 sagemaker.remote_function INFO     PWD=/\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,780 sagemaker.remote_function INFO     NVIDIA_DRIVER_CAPABILITIES=compute,utility,compat32,graphics,video\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,780 sagemaker.remote_function INFO     SAGEMAKER_MANAGED_WARMPOOL_CACHE_DIRECTORY=/opt/ml/sagemaker/warmpoolcache\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,780 sagemaker.remote_function INFO     OPEN_MPI_PATH=/opt/amazon/openmpi\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     NV_CUDA_CUDART_VERSION=12.4.127-1\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     HOME=/root\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     LANG=C.UTF-8\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     CUDA_VERSION=12.4.1\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     DMLC_INTERFACE=eth0\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     PIP_CACHE_DIR=/opt/ml/sagemaker/warmpoolcache/sm_remotefunction_user_dependencies_cache/pip\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     PYTHONIOENCODING=UTF-8\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     SHLVL=1\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     NVARCH=x86_64\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     PYTHONDONTWRITEBYTECODE=1\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     NV_CUDA_COMPAT_PACKAGE=cuda-compat-12-4\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     LD_LIBRARY_PATH=/opt/conda/lib/python3.11/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib:/opt/amazon/efa/lib:/lib/x86_64-linux-gnu:/opt/conda/lib:/usr/local/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     REMOTE_FUNCTION_SECRET_KEY=******\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     CONDA_PKGS_DIRS=/opt/ml/sagemaker/warmpoolcache/sm_remotefunction_user_dependencies_cache/conda/pkgs\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     TRAINING_JOB_NAME=train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     LC_ALL=C.UTF-8\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     EFA_PATH=/opt/amazon/efa\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     TRAINING_JOB_ARN=arn:aws:sagemaker:us-east-1:058264176820:training-job/train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     CUDA_HOME=/usr/local/cuda\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,781 sagemaker.remote_function INFO     PATH=/opt/amazon/openmpi/bin:/opt/amazon/efa/bin:/usr/local/cuda/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     DEBIAN_FRONTEND=noninteractive\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     DLC_CONTAINER_TYPE=training\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     _=/opt/conda/bin/python\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_INPUT_DATA_DIR=/opt/ml/input/data\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_OUTPUT_FAILURE=/opt/ml/output/failure\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_MASTER_ADDR=algo-1\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_MASTER_PORT=7777\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_CURRENT_INSTANCE_TYPE=ml.g5.12xlarge\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_HOSTS=['algo-1']\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_HOST_COUNT=1\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_CURRENT_HOST_RANK=0\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_NUM_CPUS=48\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_RESOURCE_CONFIG={\"current_host\": \"algo-1\", \"current_instance_type\": \"ml.g5.12xlarge\", \"current_group_name\": \"homogeneousCluster\", \"hosts\": [\"algo-1\"], \"instance_groups\": [{\"instance_group_name\": \"homogeneousCluster\", \"instance_type\": \"ml.g5.12xlarge\", \"hosts\": [\"algo-1\"]}], \"network_interface_name\": \"eth0\"}\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,782 sagemaker.remote_function INFO     SM_NPROC_PER_NODE=4\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,783 sagemaker.remote_function INFO     SM_TRAINING_ENV={\"current_host\": \"algo-1\", \"current_instance_type\": \"ml.g5.12xlarge\", \"hosts\": [\"algo-1\"], \"host_count\": 1, \"nproc_per_node\": 4, \"master_addr\": \"algo-1\", \"master_port\": 7777, \"input_config_dir\": \"/opt/ml/input/config\", \"input_data_dir\": \"/opt/ml/input/data\", \"input_dir\": \"/opt/ml/input\", \"job_name\": \"train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856\", \"model_dir\": \"/opt/ml/model\", \"network_interface_name\": \"eth0\", \"num_cpus\": 48, \"num_gpus\": 4, \"num_neurons\": 0, \"output_data_dir\": \"/opt/ml/output/data\", \"resource_config\": {\"current_host\": \"algo-1\", \"current_instance_type\": \"ml.g5.12xlarge\", \"current_group_name\": \"homogeneousCluster\", \"hosts\": [\"algo-1\"], \"instance_groups\": [{\"instance_group_name\": \"homogeneousCluster\", \"instance_type\": \"ml.g5.12xlarge\", \"hosts\": [\"algo-1\"]}], \"network_interface_name\": \"eth0\"}}\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,783 sagemaker.remote_function INFO     NCCL_SOCKET_IFNAME=eth0\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:38,783 sagemaker.remote_function INFO     NCCL_PROTO=simple\u001b[0m\n",
      "\u001b[34mINFO: Changing workspace to sagemaker_remote_function_workspace.\u001b[0m\n",
      "\u001b[34mINFO: No conda env provided. Invoking remote function with torchrun\u001b[0m\n",
      "\u001b[34mINFO: torchrun --nnodes 1 --nproc_per_node 4 --master_addr algo-1     --master_port 7777 --node_rank 0 -m sagemaker.remote_function.invoke_function \u001b[0m\n",
      "\u001b[34mW0406 21:02:40.485000 84 site-packages/torch/distributed/run.py:793] \u001b[0m\n",
      "\u001b[34mW0406 21:02:40.485000 84 site-packages/torch/distributed/run.py:793] *****************************************\u001b[0m\n",
      "\u001b[34mW0406 21:02:40.485000 84 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \u001b[0m\n",
      "\u001b[34mW0406 21:02:40.485000 84 site-packages/torch/distributed/run.py:793] *****************************************\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:42,334 sagemaker.remote_function INFO     Deserializing function code from s3://sagemaker-us-east-1-058264176820/train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856/function\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:42,343 sagemaker.remote_function INFO     Deserializing function code from s3://sagemaker-us-east-1-058264176820/train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856/function\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:42,349 sagemaker.remote_function INFO     Deserializing function code from s3://sagemaker-us-east-1-058264176820/train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856/function\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:42,351 sagemaker.remote_function INFO     Deserializing function code from s3://sagemaker-us-east-1-058264176820/train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856/function\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:47,523 sagemaker.remote_function INFO     Deserializing function arguments from s3://sagemaker-us-east-1-058264176820/train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856/arguments\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:47,523 sagemaker.remote_function INFO     Deserializing function arguments from s3://sagemaker-us-east-1-058264176820/train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856/arguments\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:47,526 sagemaker.remote_function INFO     Deserializing function arguments from s3://sagemaker-us-east-1-058264176820/train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856/arguments\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:47,537 sagemaker.remote_function INFO     Deserializing function arguments from s3://sagemaker-us-east-1-058264176820/train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856/arguments\u001b[0m\n",
      "\u001b[34m[04/06/25 21:02:47] INFO     PyTorch version 2.5.1+cu124 available. config.py:54\u001b[0m\n",
      "\u001b[34m[04/06/25 21:02:47] INFO     PyTorch version 2.5.1+cu124 available. config.py:54\u001b[0m\n",
      "\u001b[34m[04/06/25 21:02:47] INFO     PyTorch version 2.5.1+cu124 available. config.py:54\u001b[0m\n",
      "\u001b[34m[04/06/25 21:02:47] INFO     PyTorch version 2.5.1+cu124 available. config.py:54\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:47,811 sagemaker.remote_function INFO     Resolving pipeline variables\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:47,811 sagemaker.remote_function INFO     Resolving pipeline variables\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:47,811 sagemaker.remote_function INFO     Invoking the function\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:47,811 sagemaker.remote_function INFO     Invoking the function\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:47,812 sagemaker.remote_function INFO     Resolving pipeline variables\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:47,813 sagemaker.remote_function INFO     Invoking the function\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:47,815 sagemaker.remote_function INFO     Resolving pipeline variables\u001b[0m\n",
      "\u001b[34m2025-04-06 21:02:47,815 sagemaker.remote_function INFO     Invoking the function\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:136 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:136 [0] NCCL INFO Bootstrap : Using eth0:10.0.188.67<0>\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:136 [0] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:136 [0] NCCL INFO NCCL version 2.23.4+cuda12.4\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:138 [2] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:137 [1] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:139 [3] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:138 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:137 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:139 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:137 [1] NCCL INFO Bootstrap : Using eth0:10.0.188.67<0>\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:138 [2] NCCL INFO Bootstrap : Using eth0:10.0.188.67<0>\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:139 [3] NCCL INFO Bootstrap : Using eth0:10.0.188.67<0>\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:138 [2] NCCL INFO NCCL version 2.23.4+cuda12.4\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:137 [1] NCCL INFO NCCL version 2.23.4+cuda12.4\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:139 [3] NCCL INFO NCCL version 2.23.4+cuda12.4\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.12.1-aws\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NET/OFI Using Libfabric version 1.22\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NET/OFI Setting provider_filter to efa\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NET/OFI Internode latency set at 150.0 us\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NET/OFI Creating one domain per process\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.12.1-aws\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NET/OFI Using Libfabric version 1.22\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NET/OFI Setting provider_filter to efa\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.12.1-aws\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NET/OFI Using Libfabric version 1.22\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NET/OFI Internode latency set at 150.0 us\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NET/OFI Creating one domain per process\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NET/OFI Setting provider_filter to efa\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NET/OFI Internode latency set at 150.0 us\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NET/OFI Creating one domain per process\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.12.1-aws\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NET/OFI Using Libfabric version 1.22\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NET/OFI Setting provider_filter to efa\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NET/OFI Internode latency set at 150.0 us\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NET/OFI Creating one domain per process\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NET/OFI Global registrations supported\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO ncclCommInitRankConfig comm 0x55aa0b3b3530 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1b0 commId 0xd9a376b52abe1062 - Init START\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NET/OFI Global registrations supported\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NET/OFI Global registrations supported\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO ncclCommInitRankConfig comm 0x562869c3d030 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId 1e0 commId 0xd9a376b52abe1062 - Init START\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO ncclCommInitRankConfig comm 0x556f125f2070 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 1d0 commId 0xd9a376b52abe1062 - Init START\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NET/OFI Global registrations supported\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO ncclCommInitRankConfig comm 0x5573923012f0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 1c0 commId 0xd9a376b52abe1062 - Init START\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO Bootstrap timings total 0.002952 (create 0.000029, send 0.000116, recv 0.000107, ring 0.002188, delay 0.000000)\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO Bootstrap timings total 0.000564 (create 0.000030, send 0.000113, recv 0.000197, ring 0.000089, delay 0.000000)\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO Bootstrap timings total 0.002574 (create 0.000030, send 0.000116, recv 0.000113, ring 0.000088, delay 0.000000)\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO Bootstrap timings total 0.059479 (create 0.000029, send 0.000147, recv 0.059053, ring 0.000067, delay 0.000000)\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NET/OFI Global registrations supported\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NET/OFI Global registrations supported\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NET/OFI Global registrations supported\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NET/OFI Global registrations supported\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NVLS multicast support is not available on dev 2\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NVLS multicast support is not available on dev 0\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NVLS multicast support is not available on dev 1\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NVLS multicast support is not available on dev 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO comm 0x5573923012f0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO comm 0x556f125f2070 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO comm 0x55aa0b3b3530 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO comm 0x562869c3d030 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO Channel 00/04 : 0 1 2 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO Channel 01/04 : 0 1 2 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO Channel 02/04 : 0 1 2 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO Channel 03/04 : 0 1 2 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:222 [0] NCCL INFO [Proxy Service] Device 0 CPU core 14\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:219 [1] NCCL INFO [Proxy Service] Device 1 CPU core 29\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:221 [3] NCCL INFO [Proxy Service] Device 3 CPU core 36\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:224 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 10\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:223 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 20\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:226 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 6\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:225 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 30\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:220 [2] NCCL INFO [Proxy Service] Device 2 CPU core 44\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO CC Off, Multi-GPU CC Off, workFifoBytes 1048576\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO ncclCommInitRankConfig comm 0x556f125f2070 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 1d0 commId 0xd9a376b52abe1062 - Init COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO ncclCommInitRankConfig comm 0x5573923012f0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 1c0 commId 0xd9a376b52abe1062 - Init COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO ncclCommInitRankConfig comm 0x562869c3d030 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId 1e0 commId 0xd9a376b52abe1062 - Init COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:217 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.23 (kernels 0.13, alloc 0.07, bootstrap 0.00, allgathers 0.00, topo 0.01, graphs 0.00, connections 0.01, rest 0.00)\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:216 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.23 (kernels 0.13, alloc 0.08, bootstrap 0.00, allgathers 0.00, topo 0.01, graphs 0.00, connections 0.01, rest 0.00)\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:218 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.23 (kernels 0.13, alloc 0.07, bootstrap 0.00, allgathers 0.00, topo 0.01, graphs 0.00, connections 0.01, rest 0.00)\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO ncclCommInitRankConfig comm 0x55aa0b3b3530 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1b0 commId 0xd9a376b52abe1062 - Init COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:215 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.23 (kernels 0.13, alloc 0.02, bootstrap 0.06, allgathers 0.00, topo 0.01, graphs 0.00, connections 0.01, rest 0.00)\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:230 [0] NCCL INFO Channel 00 : 0[0] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:230 [0] NCCL INFO Channel 01 : 0[0] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:230 [0] NCCL INFO Channel 02 : 0[0] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:230 [0] NCCL INFO Channel 03 : 0[0] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:228 [2] NCCL INFO Channel 00 : 2[2] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:227 [1] NCCL INFO Channel 00 : 1[1] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:227 [1] NCCL INFO Channel 01 : 1[1] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:228 [2] NCCL INFO Channel 01 : 2[2] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:227 [1] NCCL INFO Channel 02 : 1[1] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:228 [2] NCCL INFO Channel 02 : 2[2] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:227 [1] NCCL INFO Channel 03 : 1[1] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:228 [2] NCCL INFO Channel 03 : 2[2] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:229 [3] NCCL INFO Channel 00 : 3[3] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:229 [3] NCCL INFO Channel 01 : 3[3] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:229 [3] NCCL INFO Channel 02 : 3[3] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:229 [3] NCCL INFO Channel 03 : 3[3] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:227 [1] NCCL INFO Channel 00 : 1[1] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:228 [2] NCCL INFO Channel 00 : 2[2] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:227 [1] NCCL INFO Channel 01 : 1[1] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:228 [2] NCCL INFO Channel 01 : 2[2] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:227 [1] NCCL INFO Channel 02 : 1[1] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:228 [2] NCCL INFO Channel 02 : 2[2] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:227 [1] NCCL INFO Channel 03 : 1[1] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:228 [2] NCCL INFO Channel 03 : 2[2] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:230 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:229 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:227 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:228 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34mDownloading model  deepseek-ai/DeepSeek-R1-Distill-Llama-8B\u001b[0m\n",
      "\u001b[34m#015Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]#015Fetching 11 files:   9%|▉         | 1/11 [00:00<00:01,  9.58it/s]#015Fetching 11 files:  27%|██▋       | 3/11 [00:00<00:00, 12.53it/s]#015Fetching 11 files:  27%|██▋       | 3/11 [00:19<00:00, 12.53it/s]#015Fetching 11 files:  64%|██████▎   | 7/11 [00:23<00:16,  4.03s/it]#015Fetching 11 files: 100%|██████████| 11/11 [00:23<00:00,  2.17s/it]\u001b[0m\n",
      "\u001b[34mModel deepseek-ai/DeepSeek-R1-Distill-Llama-8B downloaded under /tmp/tmp_folder\u001b[0m\n",
      "\u001b[34m#015Map:   0%|          | 0/450 [00:00<?, ? examples/s]#015Map:  52%|█████▏    | 234/450 [00:00<00:00, 2323.24 examples/s]#015Map: 100%|██████████| 450/450 [00:00<00:00, 2105.09 examples/s]\u001b[0m\n",
      "\u001b[34mTotal number of train samples: 450\u001b[0m\n",
      "\u001b[34m#015Map:   0%|          | 0/50 [00:00<?, ? examples/s]#015Map: 100%|██████████| 50/50 [00:00<00:00, 1777.79 examples/s]\u001b[0m\n",
      "\u001b[34mTotal number of test samples: 50\u001b[0m\n",
      "\u001b[34mflash_attention_2 init\u001b[0m\n",
      "\u001b[34mConfigurations for FSDP\u001b[0m\n",
      "\u001b[34m`low_cpu_mem_usage` was None, now default to True since model is quantized.\u001b[0m\n",
      "\u001b[34mTotal number of train samples: 450\u001b[0m\n",
      "\u001b[34m#015Map:   0%|          | 0/450 [00:00<?, ? examples/s]#015Map:   0%|          | 0/450 [00:00<?, ? examples/s]#015Map:   0%|          | 0/450 [00:00<?, ? examples/s]#015Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]#015Map:  52%|█████▏    | 235/450 [00:00<00:00, 2336.58 examples/s]#015Map:  52%|█████▏    | 235/450 [00:00<00:00, 2325.14 examples/s]#015Map:  52%|█████▏    | 235/450 [00:00<00:00, 2335.05 examples/s]#015Map: 100%|██████████| 450/450 [00:00<00:00, 2105.44 examples/s]\u001b[0m\n",
      "\u001b[34mTotal number of train samples: 450\u001b[0m\n",
      "\u001b[34m#015Map: 100%|██████████| 450/450 [00:00<00:00, 2108.11 examples/s]\u001b[0m\n",
      "\u001b[34m#015Map: 100%|██████████| 450/450 [00:00<00:00, 2095.75 examples/s]\u001b[0m\n",
      "\u001b[34mTotal number of train samples: 450\u001b[0m\n",
      "\u001b[34mTotal number of test samples: 50\u001b[0m\n",
      "\u001b[34mflash_attention_2 init\u001b[0m\n",
      "\u001b[34mConfigurations for FSDP\u001b[0m\n",
      "\u001b[34m#015Map:   0%|          | 0/50 [00:00<?, ? examples/s]#015Map:   0%|          | 0/50 [00:00<?, ? examples/s]#015Map:   0%|          | 0/50 [00:00<?, ? examples/s]#015Map: 100%|██████████| 50/50 [00:00<00:00, 1782.64 examples/s]\u001b[0m\n",
      "\u001b[34m#015Map: 100%|██████████| 50/50 [00:00<00:00, 1779.24 examples/s]\u001b[0m\n",
      "\u001b[34mTotal number of test samples: 50\u001b[0m\n",
      "\u001b[34mflash_attention_2 init\u001b[0m\n",
      "\u001b[34mConfigurations for FSDP\u001b[0m\n",
      "\u001b[34mTotal number of test samples: 50\u001b[0m\n",
      "\u001b[34mflash_attention_2 init\u001b[0m\n",
      "\u001b[34mConfigurations for FSDP\u001b[0m\n",
      "\u001b[34m#015Map: 100%|██████████| 50/50 [00:00<00:00, 1787.35 examples/s]\u001b[0m\n",
      "\u001b[34m`low_cpu_mem_usage` was None, now default to True since model is quantized.\u001b[0m\n",
      "\u001b[34m`low_cpu_mem_usage` was None, now default to True since model is quantized.\u001b[0m\n",
      "\u001b[34m`low_cpu_mem_usage` was None, now default to True since model is quantized.\u001b[0m\n",
      "\u001b[34m#015Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]#015Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]#015Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]#015Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.65s/it]#015Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.54s/it]#015Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.55s/it]#015Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.56s/it]#015Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]#015Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]\u001b[0m\n",
      "\u001b[34mgradient_checkpointing enabled\u001b[0m\n",
      "\u001b[34mtrainable params: 20,971,520 || all params: 8,051,232,768 || trainable%: 0.2605\u001b[0m\n",
      "\u001b[34m#015Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  2.08s/it]#015Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]\u001b[0m\n",
      "\u001b[34m#015Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  2.08s/it]#015Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]\u001b[0m\n",
      "\u001b[34m#015Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  2.08s/it]#015Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]\u001b[0m\n",
      "\u001b[34mgradient_checkpointing enabled\u001b[0m\n",
      "\u001b[34mgradient_checkpointing enabled\u001b[0m\n",
      "\u001b[34mgradient_checkpointing enabled\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:449 [3] NCCL INFO Channel 00 : 3[3] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:449 [3] NCCL INFO Channel 01 : 3[3] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:449 [3] NCCL INFO Channel 02 : 3[3] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:449 [3] NCCL INFO Channel 03 : 3[3] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:449 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:445 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:450 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:451 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m{'loss': 3.2829, 'grad_norm': 2.6149446964263916, 'learning_rate': 0.00018, 'epoch': 0.2}\u001b[0m\n",
      "\u001b[34m{'loss': 3.0989, 'grad_norm': 2.4547719955444336, 'learning_rate': 0.00016, 'epoch': 0.4}\u001b[0m\n",
      "\u001b[34m{'loss': 2.8313, 'grad_norm': 1.995863437652588, 'learning_rate': 0.00014, 'epoch': 0.6}\u001b[0m\n",
      "\u001b[34m{'loss': 2.6147, 'grad_norm': 1.725489616394043, 'learning_rate': 0.00012, 'epoch': 0.8}\u001b[0m\n",
      "\u001b[34m{'loss': 2.3819, 'grad_norm': 1.320157527923584, 'learning_rate': 0.0001, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m{'loss': 2.2333, 'grad_norm': 0.8521433472633362, 'learning_rate': 8e-05, 'epoch': 1.2}\u001b[0m\n",
      "\u001b[34m{'loss': 2.2374, 'grad_norm': 0.6513844132423401, 'learning_rate': 6e-05, 'epoch': 1.4}\u001b[0m\n",
      "\u001b[34m{'loss': 2.1547, 'grad_norm': 0.6822608709335327, 'learning_rate': 4e-05, 'epoch': 1.6}\u001b[0m\n",
      "\u001b[34m{'loss': 2.1382, 'grad_norm': 0.6112679839134216, 'learning_rate': 2e-05, 'epoch': 1.8}\u001b[0m\n",
      "\u001b[34m{'loss': 2.1451, 'grad_norm': 0.5678827166557312, 'learning_rate': 0.0, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m{'train_runtime': 177.3388, 'train_samples_per_second': 5.075, 'train_steps_per_second': 0.056, 'train_loss': 2.5118207931518555, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/10 [00:00<?, ?it/s]#015 10%|█         | 1/10 [00:20<03:04, 20.48s/it]#015                                              #015#015 10%|█         | 1/10 [00:20<03:04, 20.48s/it]#015 20%|██        | 2/10 [00:39<02:36, 19.52s/it]#015                                              #015#015 20%|██        | 2/10 [00:39<02:36, 19.52s/it]#015 30%|███       | 3/10 [00:56<02:09, 18.50s/it]#015                                              #015#015 30%|███       | 3/10 [00:56<02:09, 18.50s/it]#015 40%|████      | 4/10 [01:15<01:52, 18.69s/it]#015                                              #015#015 40%|████      | 4/10 [01:15<01:52, 18.69s/it]#015 50%|█████     | 5/10 [01:31<01:27, 17.51s/it]#015                                              #015#015 50%|█████     | 5/10 [01:31<01:27, 17.51s/it]#015 60%|██████    | 6/10 [01:48<01:10, 17.56s/it]#015                                              #015#015 60%|██████    | 6/10 [01:48<01:10, 17.56s/it]#015 70%|███████   | 7/10 [02:06<00:52, 17.55s/it]#015                                              #015#015 70%|███████   | 7/10 [02:06<00:52, 17.55s/it]#015 80%|████████  | 8/10 [02:22<00:34, 17.03s/it]#015                                              #015#015 80%|████████  | 8/10 [02:22<00:34, 17.03s/it]#015 90%|█████████ | 9/10 [02:41<00:17, 17.84s/it]#015                                              #015#015 90%|█████████ | 9/10 [02:41<00:17, 17.84s/it]#015100%|██████████| 10/10 [02:57<00:00, 17.08s/it]#015                                               #015#015100%|██████████| 10/10 [02:57<00:00, 17.08s/it]#015                                               #015#015100%|██████████| 10/10 [02:57<00:00, 17.08s/it]#015100%|██████████| 10/10 [02:58<00:00, 17.81s/it]\u001b[0m\n",
      "\u001b[34m#015Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s][rank0]:[W406 21:06:30.919105264 PyInterpreter.cpp:260] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)\u001b[0m\n",
      "\u001b[34m[rank0]:[W406 21:06:30.919178735 PyInterpreter.cpp:260] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)\u001b[0m\n",
      "\u001b[34m#015Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.41s/it]#015Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.07s/it]#015Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.13s/it]\u001b[0m\n",
      "\u001b[34m2025-04-06 21:07:58,332 sagemaker.remote_function INFO     Serializing the function return and uploading to s3://sagemaker-us-east-1-058264176820/train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856/results\u001b[0m\n",
      "\u001b[34m2025-04-06 21:07:58,332 sagemaker.remote_function INFO     Serializing the function return and uploading to s3://sagemaker-us-east-1-058264176820/train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856/results\u001b[0m\n",
      "\u001b[34m2025-04-06 21:07:58,332 sagemaker.remote_function INFO     Serializing the function return and uploading to s3://sagemaker-us-east-1-058264176820/train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856/results\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:492 [2] NCCL INFO misc/socket.cc:47 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:492 [2] NCCL INFO misc/socket.cc:58 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:492 [2] NCCL INFO misc/socket.cc:781 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:220 [2] NCCL INFO misc/socket.cc:832 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:493 [3] NCCL INFO misc/socket.cc:47 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:493 [3] NCCL INFO misc/socket.cc:58 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:493 [3] NCCL INFO misc/socket.cc:781 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:221 [3] NCCL INFO misc/socket.cc:832 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:494 [1] NCCL INFO misc/socket.cc:47 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:494 [1] NCCL INFO misc/socket.cc:58 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:494 [1] NCCL INFO misc/socket.cc:781 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:219 [1] NCCL INFO misc/socket.cc:832 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:138:492 [2] NCCL INFO comm 0x556f125f2070 rank 2 nranks 4 cudaDev 2 busId 1d0 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:139:493 [3] NCCL INFO comm 0x562869c3d030 rank 3 nranks 4 cudaDev 3 busId 1e0 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m2025-04-06 21:07:59,647 sagemaker.remote_function INFO     Serializing the function return and uploading to s3://sagemaker-us-east-1-058264176820/train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856/results\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:137:494 [1] NCCL INFO comm 0x5573923012f0 rank 1 nranks 4 cudaDev 1 busId 1c0 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m[rank0]:[W406 21:08:00.270315668 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:499 [0] NCCL INFO misc/socket.cc:47 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:499 [0] NCCL INFO misc/socket.cc:58 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:499 [0] NCCL INFO misc/socket.cc:781 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:222 [0] NCCL INFO misc/socket.cc:832 -> 3\u001b[0m\n",
      "\u001b[34mip-10-0-188-67:136:499 [0] NCCL INFO comm 0x55aa0b3b3530 rank 0 nranks 4 cudaDev 0 busId 1b0 - Abort COMPLETE\u001b[0m\n",
      "\n",
      "2025-04-06 21:08:12 Uploading - Uploading generated training model\n",
      "2025-04-06 21:09:10 Completed - Training job completed\n",
      "Training seconds: 668\n",
      "Billable seconds: 668\n"
     ]
    }
   ],
   "source": [
    "train_fn(\n",
    "    model_id,\n",
    "    train_ds=train_dataset,\n",
    "    test_ds=test_dataset,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=24,\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=True,\n",
    "    num_train_epochs=2,\n",
    "    fsdp=\"full_shard auto_wrap offload\",\n",
    "    fsdp_config={\n",
    "        'backward_prefetch': 'backward_pre',\n",
    "        'cpu_ram_efficient_loading': True,\n",
    "        'offload_params': True,\n",
    "        'forward_prefetch': False,\n",
    "        'use_orig_params': False\n",
    "    },\n",
    "    merge_weights=True,\n",
    "    mlflow_uri=os.environ.get(\"MLFLOW_URI\", None),\n",
    "    mlflow_experiment_name=os.environ.get(\"MLFLOW_EXPERIMENT_NAME\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Fine-Tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:08.515277Z",
     "start_time": "2023-11-20T18:41:08.503555Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T13:45:11.757861Z",
     "start_time": "2023-09-03T13:45:11.747993Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "job_prefix = f\"train-{model_id.split('/')[-1].replace('.', '-')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_job_name(job_name_prefix):\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "    matching_jobs = []\n",
    "    next_token = None\n",
    "\n",
    "    while True:\n",
    "        # Prepare the search parameters\n",
    "        search_params = {\n",
    "            'Resource': 'TrainingJob',\n",
    "            'SearchExpression': {\n",
    "                'Filters': [\n",
    "                    {\n",
    "                        'Name': 'TrainingJobName',\n",
    "                        'Operator': 'Contains',\n",
    "                        'Value': job_name_prefix\n",
    "                    },\n",
    "                    {\n",
    "                        'Name': 'TrainingJobStatus',\n",
    "                        'Operator': 'Equals',\n",
    "                        'Value': \"Completed\"\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            'SortBy': 'CreationTime',\n",
    "            'SortOrder': 'Descending',\n",
    "            'MaxResults': 100\n",
    "        }\n",
    "\n",
    "        # Add NextToken if we have one\n",
    "        if next_token:\n",
    "            search_params['NextToken'] = next_token\n",
    "\n",
    "        # Make the search request\n",
    "        search_response = sagemaker_client.search(**search_params)\n",
    "\n",
    "        # Filter and add matching jobs\n",
    "        matching_jobs.extend([\n",
    "            job['TrainingJob']['TrainingJobName'] \n",
    "            for job in search_response['Results']\n",
    "            if job['TrainingJob']['TrainingJobName'].startswith(job_name_prefix)\n",
    "        ])\n",
    "\n",
    "        # Check if we have more results to fetch\n",
    "        next_token = search_response.get('NextToken')\n",
    "        if not next_token or matching_jobs:  # Stop if we found at least one match or no more results\n",
    "            break\n",
    "\n",
    "    if not matching_jobs:\n",
    "        raise ValueError(f\"No completed training jobs found starting with prefix '{job_name_prefix}'\")\n",
    "\n",
    "    return matching_jobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train-DeepSeek-R1-Distill-Llama-8B-2025-04-06-20-55-17-856'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = get_last_job_name(job_prefix)\n",
    "\n",
    "job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Deploy Llama 3.2 3B Instruct fine-tuned model using Amazon SageMaker AI Endpoints and Amazon SageMaker Large Model Inference (LMI) Container with the SageMaker Python SDK \n",
    "\n",
    "In this example you will deploy your model using [SageMaker's Large Model Inference (LMI) Containers](https://docs.djl.ai/master/docs/serving/serving/docs/lmi/index.html).\n",
    "\n",
    "LMI containers are a set of high-performance Docker Containers purpose built for large language model (LLM) inference. With these containers, you can leverage high performance open-source inference libraries like vLLM, TensorRT-LLM, Transformers NeuronX to deploy LLMs on AWS SageMaker Endpoints. These containers bundle together a model server with open-source inference libraries to deliver an all-in-one LLM serving solution.\n",
    "\n",
    "The LMI container supports a variety of different backends, outlined in the table below. \n",
    "\n",
    "The model for this example can be deployed using the vLLM backend, which corresponds to the `djl-lmi` container image.\n",
    "\n",
    "| Backend | SageMakerDLC | Example URI |\n",
    "| --- | --- | --- |\n",
    "|vLLM|djl-lmi|763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.29.0-lmi11.0.0-cu124\n",
    "|lmi-dist|djl-lmi|763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.29.0-lmi11.0.0-cu124\n",
    "|hf-accelerate|djl-lmi|763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.29.0-lmi11.0.0-cu124\n",
    "|tensorrt-llm|djl-tensorrtllm|763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.29.0-tensorrtllm0.11.0-cu124\n",
    "|transformers-neuronx|djl-neuronx|763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.29.0-neuronx-sdk2.19.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:10.492877Z",
     "start_time": "2023-11-20T18:41:10.488495Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "instance_count = 1\n",
    "instance_type = \"ml.g5.4xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/06/25 21:10:10] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Ignoring unnecessary instance type: <span style=\"color: #e100e1; text-decoration-color: #e100e1; font-style: italic\">None</span>.                            <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py#530\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">530</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/06/25 21:10:10]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Ignoring unnecessary instance type: \u001b[3;38;2;225;0;225mNone\u001b[0m.                            \u001b]8;id=572732;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=139841;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py#530\u001b\\\u001b[2m530\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.30.0-lmi12.0.0-cu124'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"djl-lmi\",\n",
    "    region=sagemaker_session.boto_session.region_name,\n",
    "    version=\"latest\"\n",
    ")\n",
    "\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:12.433399Z",
     "start_time": "2023-11-20T18:41:11.963091Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Applied value from config key = SageMaker.Model.EnableNetworkIsolation\n"
     ]
    }
   ],
   "source": [
    "if default_prefix:\n",
    "    model_data = f\"s3://{bucket_name}/{default_prefix}/{job_name}/{job_name}/output/model.tar.gz\"\n",
    "else:\n",
    "    model_data = f\"s3://{bucket_name}/{job_name}/{job_name}/output/model.tar.gz\"\n",
    "\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=model_data,\n",
    "    role=get_execution_role(),\n",
    "    env={\n",
    "        'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "        'OPTION_TRUST_REMOTE_CODE': 'true',\n",
    "        'OPTION_ROLLING_BATCH': \"vllm\",\n",
    "        'OPTION_DTYPE': 'bf16',\n",
    "        'OPTION_TENSOR_PARALLEL_DEGREE': 'max',\n",
    "        'OPTION_MAX_ROLLING_BATCH_SIZE': '1',\n",
    "        'OPTION_MODEL_LOADING_TIMEOUT': '3600',\n",
    "        'OPTION_MAX_MODEL_LEN': '4096'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "endpoint_name = f\"{model_id.split('/')[-1].replace('.', '-')}-finetuned\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:45:49.265298Z",
     "start_time": "2023-11-20T18:41:14.621743Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/06/25 21:10:23] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: djl-inference-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-06-21-10-22-407        <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/06/25 21:10:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: djl-inference-\u001b[1;36m2025\u001b[0m-04-06-21-10-22-407        \u001b]8;id=800924;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=550024;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/06/25 21:10:24] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#5889\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5889</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         DeepSeek-R1-Distill-Llama-8B-finetuned                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/06/25 21:10:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=118987;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=880377;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#5889\u001b\\\u001b[2m5889\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         DeepSeek-R1-Distill-Llama-8B-finetuned                                 \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/06/25 21:10:25] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name DeepSeek-R1-Distill-Llama-8B-finetuned     <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4711\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4711</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/06/25 21:10:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name DeepSeek-R1-Distill-Llama-8B-finetuned     \u001b]8;id=251450;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=40751;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4711\u001b\\\u001b[2m4711\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(\n",
    "    endpoint_name=endpoint_name,\n",
    "    initial_instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    container_startup_health_check_timeout=health_check_timeout,\n",
    "    model_data_download_timeout=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "endpoint_name = f\"{model_id.split('/')[-1].replace('.', '-')}-finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek-R1-Distill-Llama-8B-finetuned\n"
     ]
    }
   ],
   "source": [
    "print(endpoint_name)\n",
    "\n",
    "# DeepSeek-R1-Distill-Llama-8B-finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=sagemaker.serializers.JSONSerializer(),\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summarization_prompts(data_point):\n",
    "    full_prompt =f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "                    You are an AI assistant trained to summarize conversations. Provide a concise summary of the dialogue, capturing the key points and overall context.\n",
    "                    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "                    Summarize the following conversation:\n",
    "\n",
    "                    {data_point[\"dialogue\"]}\n",
    "                    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "                    Here's a concise summary of the conversation in a single sentence:\n",
    "\n",
    "                    <|eot_id|>\"\"\"\n",
    "    return {\"prompt\": full_prompt}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a random prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2681b42c8cef47e6a733b7c026747ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e90f996daf34eb9b046f5eae6cd83e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "samsum.py:   0%|          | 0.00/3.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for Samsung/samsum contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/Samsung/samsum.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766d239d52294eb18bf66f066df52ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/14732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2694b7cc6c6a44ecb63aaadd380ce5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c70ca03bcd4cbbaba294e8c9b10b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n'\n",
      "           '                    You are an AI assistant trained to summarize '\n",
      "           'conversations. Provide a concise summary of the dialogue, '\n",
      "           'capturing the key points and overall context.\\n'\n",
      "           '                    '\n",
      "           '<|eot_id|><|start_header_id|>user<|end_header_id|>\\n'\n",
      "           '                    Summarize the following conversation:\\n'\n",
      "           '\\n'\n",
      "           '                    Gina: Hey love, do you have a free usb by any '\n",
      "           'chance?\\r\\n'\n",
      "           'Monica: Yes, I do :)\\r\\n'\n",
      "           'Gina: Can I come up to your office?\\r\\n'\n",
      "           \"Monica: Of course, usb's ready\\r\\n\"\n",
      "           'Monica: 2nd floor, room 112\\r\\n'\n",
      "           'Gina: Thanks!\\n'\n",
      "           '                    '\n",
      "           '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n'\n",
      "           \"                    Here's a concise summary of the conversation \"\n",
      "           'in a single sentence:\\n'\n",
      "           '\\n'\n",
      "           '                    <|eot_id|>'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# HF dataset that we will be working with \n",
    "dataset_name=\"Samsung/samsum\"\n",
    "    \n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset(dataset_name, split=\"test\")\n",
    "\n",
    "random_row = dataset.shuffle().select(range(1))[0]\n",
    "\n",
    "random_prompt=create_summarization_prompts(random_row)\n",
    "pprint(random_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, I\\'m trying to summarize a conversation between Gina and Monica. Gina asks Monica if she has a free USB. Monica says yes and mentions she\\'s on the second floor, room 112. I need to capture the key points: the request for a USB and the location. I should keep it concise and clear. Let me see, \"Gina asks Monica for a USB and is directed to Monica\\'s office on the second floor, room 112.\" That covers both requests and the location. It\\'s a single sentence and straightforward. I think that works.\\n</think>\\n\\nGina asks Monica for a USB and is directed to Monica\\'s office on the second floor, room 112.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = predictor.predict(\n",
    "    {\n",
    "        \"inputs\": random_prompt['prompt'],\n",
    "        \"parameters\": {\n",
    "            \"do_sample\":True,\n",
    "            \"max_new_tokens\":200,\n",
    "            \"top_p\":0.95,\n",
    "            \"top_k\":50,\n",
    "            \"temperature\":0.7,\n",
    "            \"stop\": ['<|eot_id|>', '<|end_of_text|>']\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "response['generated_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Delete Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:48:55.153276Z",
     "start_time": "2023-11-20T18:48:54.165351Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predictor.delete_model()\n",
    "# predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g5.24xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
